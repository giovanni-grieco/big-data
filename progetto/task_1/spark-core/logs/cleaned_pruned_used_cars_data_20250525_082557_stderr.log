25/05/25 08:25:59 INFO SparkContext: Running Spark version 3.5.5
25/05/25 08:25:59 INFO SparkContext: OS info Linux, 6.14.6-300.fc42.x86_64, amd64
25/05/25 08:25:59 INFO SparkContext: Java version 11.0.26
25/05/25 08:25:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/05/25 08:25:59 INFO ResourceUtils: ==============================================================
25/05/25 08:25:59 INFO ResourceUtils: No custom resources configured for spark.driver.
25/05/25 08:25:59 INFO ResourceUtils: ==============================================================
25/05/25 08:25:59 INFO SparkContext: Submitted application: task 1
25/05/25 08:25:59 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/05/25 08:25:59 INFO ResourceProfile: Limiting resource is cpu
25/05/25 08:25:59 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/05/25 08:25:59 INFO SecurityManager: Changing view acls to: giovanni
25/05/25 08:25:59 INFO SecurityManager: Changing modify acls to: giovanni
25/05/25 08:25:59 INFO SecurityManager: Changing view acls groups to: 
25/05/25 08:25:59 INFO SecurityManager: Changing modify acls groups to: 
25/05/25 08:25:59 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: giovanni; groups with view permissions: EMPTY; users with modify permissions: giovanni; groups with modify permissions: EMPTY
25/05/25 08:25:59 INFO Utils: Successfully started service 'sparkDriver' on port 34977.
25/05/25 08:25:59 INFO SparkEnv: Registering MapOutputTracker
25/05/25 08:25:59 INFO SparkEnv: Registering BlockManagerMaster
25/05/25 08:25:59 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/05/25 08:25:59 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/05/25 08:25:59 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/05/25 08:25:59 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-02716a3e-a78d-4856-b215-038c5ab4c2d3
25/05/25 08:25:59 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
25/05/25 08:25:59 INFO SparkEnv: Registering OutputCommitCoordinator
25/05/25 08:25:59 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
25/05/25 08:25:59 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/05/25 08:25:59 INFO Executor: Starting executor ID driver on host desktop-fedora
25/05/25 08:25:59 INFO Executor: OS info Linux, 6.14.6-300.fc42.x86_64, amd64
25/05/25 08:25:59 INFO Executor: Java version 11.0.26
25/05/25 08:25:59 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
25/05/25 08:25:59 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@7c6dd208 for default.
25/05/25 08:25:59 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37729.
25/05/25 08:25:59 INFO NettyBlockTransferService: Server created on desktop-fedora:37729
25/05/25 08:25:59 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/05/25 08:25:59 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, desktop-fedora, 37729, None)
25/05/25 08:25:59 INFO BlockManagerMasterEndpoint: Registering block manager desktop-fedora:37729 with 434.4 MiB RAM, BlockManagerId(driver, desktop-fedora, 37729, None)
25/05/25 08:25:59 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, desktop-fedora, 37729, None)
25/05/25 08:25:59 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, desktop-fedora, 37729, None)
25/05/25 08:26:00 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 222.2 KiB, free 434.2 MiB)
25/05/25 08:26:00 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 33.2 KiB, free 434.2 MiB)
25/05/25 08:26:00 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on desktop-fedora:37729 (size: 33.2 KiB, free: 434.4 MiB)
25/05/25 08:26:00 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:0
25/05/25 08:26:00 INFO FileInputFormat: Total input files to process : 1
25/05/25 08:26:00 INFO deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
25/05/25 08:26:00 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
25/05/25 08:26:00 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/05/25 08:26:00 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/05/25 08:26:00 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:83
25/05/25 08:26:00 INFO DAGScheduler: Registering RDD 3 (reduceByKey at /home/giovanni/Projects/big-data/progetto/task_1/spark-core/spark-job.py:55) as input to shuffle 0
25/05/25 08:26:00 INFO DAGScheduler: Got job 0 (runJob at SparkHadoopWriter.scala:83) with 53 output partitions
25/05/25 08:26:00 INFO DAGScheduler: Final stage: ResultStage 1 (runJob at SparkHadoopWriter.scala:83)
25/05/25 08:26:00 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
25/05/25 08:26:00 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
25/05/25 08:26:00 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[3] at reduceByKey at /home/giovanni/Projects/big-data/progetto/task_1/spark-core/spark-job.py:55), which has no missing parents
25/05/25 08:26:00 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 15.1 KiB, free 434.1 MiB)
25/05/25 08:26:00 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 9.2 KiB, free 434.1 MiB)
25/05/25 08:26:00 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on desktop-fedora:37729 (size: 9.2 KiB, free: 434.4 MiB)
25/05/25 08:26:00 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1585
25/05/25 08:26:00 INFO DAGScheduler: Submitting 53 missing tasks from ShuffleMapStage 0 (PairwiseRDD[3] at reduceByKey at /home/giovanni/Projects/big-data/progetto/task_1/spark-core/spark-job.py:55) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
25/05/25 08:26:00 INFO TaskSchedulerImpl: Adding task set 0.0 with 53 tasks resource profile 0
25/05/25 08:26:00 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (desktop-fedora, executor driver, partition 0, NODE_LOCAL, 9079 bytes) 
25/05/25 08:26:00 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1) (desktop-fedora, executor driver, partition 1, NODE_LOCAL, 9079 bytes) 
25/05/25 08:26:00 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2) (desktop-fedora, executor driver, partition 2, NODE_LOCAL, 9079 bytes) 
25/05/25 08:26:00 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3) (desktop-fedora, executor driver, partition 3, NODE_LOCAL, 9079 bytes) 
25/05/25 08:26:00 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4) (desktop-fedora, executor driver, partition 4, NODE_LOCAL, 9079 bytes) 
25/05/25 08:26:00 INFO TaskSetManager: Starting task 5.0 in stage 0.0 (TID 5) (desktop-fedora, executor driver, partition 5, NODE_LOCAL, 9079 bytes) 
25/05/25 08:26:00 INFO TaskSetManager: Starting task 6.0 in stage 0.0 (TID 6) (desktop-fedora, executor driver, partition 6, NODE_LOCAL, 9079 bytes) 
25/05/25 08:26:00 INFO TaskSetManager: Starting task 7.0 in stage 0.0 (TID 7) (desktop-fedora, executor driver, partition 7, NODE_LOCAL, 9079 bytes) 
25/05/25 08:26:00 INFO Executor: Running task 7.0 in stage 0.0 (TID 7)
25/05/25 08:26:00 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
25/05/25 08:26:00 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
25/05/25 08:26:00 INFO Executor: Running task 6.0 in stage 0.0 (TID 6)
25/05/25 08:26:00 INFO Executor: Running task 5.0 in stage 0.0 (TID 5)
25/05/25 08:26:00 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
25/05/25 08:26:00 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)
25/05/25 08:26:00 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
25/05/25 08:26:00 INFO HadoopRDD: Input split: hdfs://localhost:9000/user/giovanni/input/cleaned_pruned_used_cars_data.csv:0+134217728
25/05/25 08:26:00 INFO HadoopRDD: Input split: hdfs://localhost:9000/user/giovanni/input/cleaned_pruned_used_cars_data.csv:134217728+134217728
25/05/25 08:26:00 INFO HadoopRDD: Input split: hdfs://localhost:9000/user/giovanni/input/cleaned_pruned_used_cars_data.csv:268435456+134217728
25/05/25 08:26:00 INFO HadoopRDD: Input split: hdfs://localhost:9000/user/giovanni/input/cleaned_pruned_used_cars_data.csv:536870912+134217728
25/05/25 08:26:00 INFO HadoopRDD: Input split: hdfs://localhost:9000/user/giovanni/input/cleaned_pruned_used_cars_data.csv:805306368+134217728
25/05/25 08:26:00 INFO HadoopRDD: Input split: hdfs://localhost:9000/user/giovanni/input/cleaned_pruned_used_cars_data.csv:939524096+134217728
25/05/25 08:26:00 INFO HadoopRDD: Input split: hdfs://localhost:9000/user/giovanni/input/cleaned_pruned_used_cars_data.csv:671088640+134217728
25/05/25 08:26:00 INFO HadoopRDD: Input split: hdfs://localhost:9000/user/giovanni/input/cleaned_pruned_used_cars_data.csv:402653184+134217728
25/05/25 08:26:01 INFO PythonRunner: Times: total = 906, boot = 292, init = 46, finish = 568
25/05/25 08:26:01 INFO PythonRunner: Times: total = 932, boot = 306, init = 31, finish = 595
25/05/25 08:26:01 INFO PythonRunner: Times: total = 867, boot = 299, init = 32, finish = 536
25/05/25 08:26:01 INFO PythonRunner: Times: total = 994, boot = 294, init = 41, finish = 659
25/05/25 08:26:01 INFO PythonRunner: Times: total = 968, boot = 303, init = 41, finish = 624
25/05/25 08:26:01 INFO PythonRunner: Times: total = 993, boot = 324, init = 46, finish = 623
25/05/25 08:26:01 INFO PythonRunner: Times: total = 931, boot = 296, init = 43, finish = 592
25/05/25 08:26:01 INFO Executor: Finished task 5.0 in stage 0.0 (TID 5). 1720 bytes result sent to driver
25/05/25 08:26:01 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1677 bytes result sent to driver
25/05/25 08:26:01 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1720 bytes result sent to driver
25/05/25 08:26:01 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1720 bytes result sent to driver
25/05/25 08:26:01 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1677 bytes result sent to driver
25/05/25 08:26:01 INFO Executor: Finished task 6.0 in stage 0.0 (TID 6). 1720 bytes result sent to driver
25/05/25 08:26:01 INFO TaskSetManager: Starting task 8.0 in stage 0.0 (TID 8) (desktop-fedora, executor driver, partition 8, NODE_LOCAL, 9079 bytes) 
25/05/25 08:26:01 INFO Executor: Running task 8.0 in stage 0.0 (TID 8)
25/05/25 08:26:01 INFO TaskSetManager: Starting task 9.0 in stage 0.0 (TID 9) (desktop-fedora, executor driver, partition 9, NODE_LOCAL, 9079 bytes) 
25/05/25 08:26:01 INFO Executor: Running task 9.0 in stage 0.0 (TID 9)
25/05/25 08:26:01 INFO Executor: Finished task 7.0 in stage 0.0 (TID 7). 1677 bytes result sent to driver
25/05/25 08:26:01 INFO TaskSetManager: Starting task 10.0 in stage 0.0 (TID 10) (desktop-fedora, executor driver, partition 10, NODE_LOCAL, 9079 bytes) 
25/05/25 08:26:01 INFO Executor: Running task 10.0 in stage 0.0 (TID 10)
25/05/25 08:26:01 INFO TaskSetManager: Starting task 11.0 in stage 0.0 (TID 11) (desktop-fedora, executor driver, partition 11, NODE_LOCAL, 9079 bytes) 
25/05/25 08:26:01 INFO Executor: Running task 11.0 in stage 0.0 (TID 11)
25/05/25 08:26:01 INFO TaskSetManager: Starting task 12.0 in stage 0.0 (TID 12) (desktop-fedora, executor driver, partition 12, NODE_LOCAL, 9079 bytes) 
25/05/25 08:26:01 INFO Executor: Running task 12.0 in stage 0.0 (TID 12)
25/05/25 08:26:01 INFO TaskSetManager: Starting task 13.0 in stage 0.0 (TID 13) (desktop-fedora, executor driver, partition 13, NODE_LOCAL, 9079 bytes) 
25/05/25 08:26:01 INFO PythonRunner: Times: total = 916, boot = 301, init = 33, finish = 582
25/05/25 08:26:01 INFO HadoopRDD: Input split: hdfs://localhost:9000/user/giovanni/input/cleaned_pruned_used_cars_data.csv:1207959552+134217728
25/05/25 08:26:01 INFO HadoopRDD: Input split: hdfs://localhost:9000/user/giovanni/input/cleaned_pruned_used_cars_data.csv:1073741824+134217728
25/05/25 08:26:01 INFO Executor: Running task 13.0 in stage 0.0 (TID 13)
25/05/25 08:26:01 INFO TaskSetManager: Finished task 6.0 in stage 0.0 (TID 6) in 1336 ms on desktop-fedora (executor driver) (1/53)
25/05/25 08:26:01 INFO HadoopRDD: Input split: hdfs://localhost:9000/user/giovanni/input/cleaned_pruned_used_cars_data.csv:1476395008+134217728
25/05/25 08:26:01 INFO HadoopRDD: Input split: hdfs://localhost:9000/user/giovanni/input/cleaned_pruned_used_cars_data.csv:1342177280+134217728
25/05/25 08:26:01 INFO HadoopRDD: Input split: hdfs://localhost:9000/user/giovanni/input/cleaned_pruned_used_cars_data.csv:1610612736+134217728
25/05/25 08:26:01 INFO TaskSetManager: Finished task 5.0 in stage 0.0 (TID 5) in 1340 ms on desktop-fedora (executor driver) (2/53)
25/05/25 08:26:01 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 1341 ms on desktop-fedora (executor driver) (3/53)
25/05/25 08:26:01 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1350 ms on desktop-fedora (executor driver) (4/53)
25/05/25 08:26:01 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 1343 ms on desktop-fedora (executor driver) (5/53)
25/05/25 08:26:01 INFO HadoopRDD: Input split: hdfs://localhost:9000/user/giovanni/input/cleaned_pruned_used_cars_data.csv:1744830464+134217728
25/05/25 08:26:01 INFO TaskSetManager: Starting task 14.0 in stage 0.0 (TID 14) (desktop-fedora, executor driver, partition 14, NODE_LOCAL, 9079 bytes) 
25/05/25 08:26:01 INFO Executor: Running task 14.0 in stage 0.0 (TID 14)
25/05/25 08:26:01 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 1346 ms on desktop-fedora (executor driver) (6/53)
25/05/25 08:26:01 INFO TaskSetManager: Finished task 7.0 in stage 0.0 (TID 7) in 1346 ms on desktop-fedora (executor driver) (7/53)
25/05/25 08:26:01 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 1677 bytes result sent to driver
25/05/25 08:26:01 INFO PythonAccumulatorV2: Connected to AccumulatorServer at host: 127.0.0.1 port: 57449
25/05/25 08:26:01 INFO HadoopRDD: Input split: hdfs://localhost:9000/user/giovanni/input/cleaned_pruned_used_cars_data.csv:1879048192+134217728
25/05/25 08:26:01 INFO TaskSetManager: Starting task 15.0 in stage 0.0 (TID 15) (desktop-fedora, executor driver, partition 15, NODE_LOCAL, 9079 bytes) 
25/05/25 08:26:01 INFO Executor: Running task 15.0 in stage 0.0 (TID 15)
25/05/25 08:26:01 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 1352 ms on desktop-fedora (executor driver) (8/53)
25/05/25 08:26:01 INFO HadoopRDD: Input split: hdfs://localhost:9000/user/giovanni/input/cleaned_pruned_used_cars_data.csv:2013265920+134217728
25/05/25 08:26:02 INFO PythonRunner: Times: total = 488, boot = -311, init = 353, finish = 446
25/05/25 08:26:02 INFO Executor: Finished task 14.0 in stage 0.0 (TID 14). 1677 bytes result sent to driver
25/05/25 08:26:02 INFO TaskSetManager: Starting task 16.0 in stage 0.0 (TID 16) (desktop-fedora, executor driver, partition 16, NODE_LOCAL, 9079 bytes) 
25/05/25 08:26:02 INFO Executor: Running task 16.0 in stage 0.0 (TID 16)
25/05/25 08:26:02 INFO TaskSetManager: Finished task 14.0 in stage 0.0 (TID 14) in 622 ms on desktop-fedora (executor driver) (9/53)
25/05/25 08:26:02 INFO HadoopRDD: Input split: hdfs://localhost:9000/user/giovanni/input/cleaned_pruned_used_cars_data.csv:2147483648+134217728
25/05/25 08:26:02 INFO PythonRunner: Times: total = 513, boot = -278, init = 316, finish = 475
25/05/25 08:26:02 INFO Executor: Finished task 13.0 in stage 0.0 (TID 13). 1677 bytes result sent to driver
25/05/25 08:26:02 INFO TaskSetManager: Starting task 17.0 in stage 0.0 (TID 17) (desktop-fedora, executor driver, partition 17, NODE_LOCAL, 9079 bytes) 
25/05/25 08:26:02 INFO Executor: Running task 17.0 in stage 0.0 (TID 17)
25/05/25 08:26:02 INFO TaskSetManager: Finished task 13.0 in stage 0.0 (TID 13) in 643 ms on desktop-fedora (executor driver) (10/53)
25/05/25 08:26:02 INFO HadoopRDD: Input split: hdfs://localhost:9000/user/giovanni/input/cleaned_pruned_used_cars_data.csv:2281701376+134217728
25/05/25 08:26:02 INFO PythonRunner: Times: total = 560, boot = -293, init = 321, finish = 532
25/05/25 08:26:02 INFO PythonRunner: Times: total = 597, boot = -309, init = 317, finish = 589
25/05/25 08:26:02 INFO Executor: Finished task 8.0 in stage 0.0 (TID 8). 1677 bytes result sent to driver
25/05/25 08:26:02 INFO TaskSetManager: Starting task 18.0 in stage 0.0 (TID 18) (desktop-fedora, executor driver, partition 18, NODE_LOCAL, 9079 bytes) 
25/05/25 08:26:02 INFO TaskSetManager: Finished task 8.0 in stage 0.0 (TID 8) in 676 ms on desktop-fedora (executor driver) (11/53)
25/05/25 08:26:02 INFO Executor: Running task 18.0 in stage 0.0 (TID 18)
25/05/25 08:26:02 INFO Executor: Finished task 9.0 in stage 0.0 (TID 9). 1677 bytes result sent to driver
25/05/25 08:26:02 INFO TaskSetManager: Starting task 19.0 in stage 0.0 (TID 19) (desktop-fedora, executor driver, partition 19, NODE_LOCAL, 9079 bytes) 
25/05/25 08:26:02 INFO Executor: Running task 19.0 in stage 0.0 (TID 19)
25/05/25 08:26:02 INFO TaskSetManager: Finished task 9.0 in stage 0.0 (TID 9) in 677 ms on desktop-fedora (executor driver) (12/53)
25/05/25 08:26:02 INFO HadoopRDD: Input split: hdfs://localhost:9000/user/giovanni/input/cleaned_pruned_used_cars_data.csv:2415919104+134217728
25/05/25 08:26:02 INFO HadoopRDD: Input split: hdfs://localhost:9000/user/giovanni/input/cleaned_pruned_used_cars_data.csv:2550136832+134217728
25/05/25 08:26:02 INFO PythonRunner: Times: total = 583, boot = -324, init = 363, finish = 544
25/05/25 08:26:02 INFO Executor: Finished task 15.0 in stage 0.0 (TID 15). 1677 bytes result sent to driver
25/05/25 08:26:02 INFO PythonRunner: Times: total = 612, boot = -347, init = 390, finish = 569
25/05/25 08:26:02 INFO TaskSetManager: Starting task 20.0 in stage 0.0 (TID 20) (desktop-fedora, executor driver, partition 20, NODE_LOCAL, 9079 bytes) 
25/05/25 08:26:02 INFO Executor: Running task 20.0 in stage 0.0 (TID 20)
25/05/25 08:26:02 INFO TaskSetManager: Finished task 15.0 in stage 0.0 (TID 15) in 688 ms on desktop-fedora (executor driver) (13/53)
25/05/25 08:26:02 INFO Executor: Finished task 10.0 in stage 0.0 (TID 10). 1677 bytes result sent to driver
25/05/25 08:26:02 INFO TaskSetManager: Starting task 21.0 in stage 0.0 (TID 21) (desktop-fedora, executor driver, partition 21, NODE_LOCAL, 9079 bytes) 
25/05/25 08:26:02 INFO TaskSetManager: Finished task 10.0 in stage 0.0 (TID 10) in 709 ms on desktop-fedora (executor driver) (14/53)
25/05/25 08:26:02 INFO Executor: Running task 21.0 in stage 0.0 (TID 21)
25/05/25 08:26:02 INFO HadoopRDD: Input split: hdfs://localhost:9000/user/giovanni/input/cleaned_pruned_used_cars_data.csv:2684354560+134217728
25/05/25 08:26:02 INFO HadoopRDD: Input split: hdfs://localhost:9000/user/giovanni/input/cleaned_pruned_used_cars_data.csv:2818572288+134217728
25/05/25 08:26:02 INFO PythonRunner: Times: total = 606, boot = -246, init = 286, finish = 566
25/05/25 08:26:02 INFO Executor: Finished task 11.0 in stage 0.0 (TID 11). 1677 bytes result sent to driver
25/05/25 08:26:02 INFO TaskSetManager: Starting task 22.0 in stage 0.0 (TID 22) (desktop-fedora, executor driver, partition 22, NODE_LOCAL, 9079 bytes) 
25/05/25 08:26:02 INFO Executor: Running task 22.0 in stage 0.0 (TID 22)
25/05/25 08:26:02 INFO TaskSetManager: Finished task 11.0 in stage 0.0 (TID 11) in 725 ms on desktop-fedora (executor driver) (15/53)
25/05/25 08:26:02 INFO PythonRunner: Times: total = 630, boot = -272, init = 311, finish = 591
25/05/25 08:26:02 INFO HadoopRDD: Input split: hdfs://localhost:9000/user/giovanni/input/cleaned_pruned_used_cars_data.csv:2952790016+134217728
25/05/25 08:26:02 INFO Executor: Finished task 12.0 in stage 0.0 (TID 12). 1677 bytes result sent to driver
25/05/25 08:26:02 INFO TaskSetManager: Starting task 23.0 in stage 0.0 (TID 23) (desktop-fedora, executor driver, partition 23, NODE_LOCAL, 9079 bytes) 
25/05/25 08:26:02 INFO Executor: Running task 23.0 in stage 0.0 (TID 23)
25/05/25 08:26:02 INFO TaskSetManager: Finished task 12.0 in stage 0.0 (TID 12) in 742 ms on desktop-fedora (executor driver) (16/53)
25/05/25 08:26:02 INFO HadoopRDD: Input split: hdfs://localhost:9000/user/giovanni/input/cleaned_pruned_used_cars_data.csv:3087007744+134217728
25/05/25 08:26:03 INFO PythonRunner: Times: total = 487, boot = -86, init = 89, finish = 484
25/05/25 08:26:03 INFO PythonRunner: Times: total = 431, boot = -83, init = 86, finish = 428
25/05/25 08:26:03 INFO Executor: Finished task 19.0 in stage 0.0 (TID 19). 1677 bytes result sent to driver
25/05/25 08:26:03 INFO Executor: Finished task 21.0 in stage 0.0 (TID 21). 1720 bytes result sent to driver
25/05/25 08:26:03 INFO TaskSetManager: Starting task 24.0 in stage 0.0 (TID 24) (desktop-fedora, executor driver, partition 24, NODE_LOCAL, 9079 bytes) 
25/05/25 08:26:03 INFO TaskSetManager: Finished task 19.0 in stage 0.0 (TID 19) in 557 ms on desktop-fedora (executor driver) (17/53)
25/05/25 08:26:03 INFO Executor: Running task 24.0 in stage 0.0 (TID 24)
25/05/25 08:26:03 INFO TaskSetManager: Finished task 21.0 in stage 0.0 (TID 21) in 526 ms on desktop-fedora (executor driver) (18/53)
25/05/25 08:26:03 INFO TaskSetManager: Starting task 25.0 in stage 0.0 (TID 25) (desktop-fedora, executor driver, partition 25, NODE_LOCAL, 9079 bytes) 
25/05/25 08:26:03 INFO Executor: Running task 25.0 in stage 0.0 (TID 25)
25/05/25 08:26:03 INFO HadoopRDD: Input split: hdfs://localhost:9000/user/giovanni/input/cleaned_pruned_used_cars_data.csv:3221225472+134217728
25/05/25 08:26:03 INFO HadoopRDD: Input split: hdfs://localhost:9000/user/giovanni/input/cleaned_pruned_used_cars_data.csv:3355443200+134217728
25/05/25 08:26:03 INFO PythonRunner: Times: total = 561, boot = -95, init = 98, finish = 558
25/05/25 08:26:03 INFO PythonRunner: Times: total = 539, boot = -59, init = 63, finish = 535
25/05/25 08:26:03 INFO Executor: Finished task 18.0 in stage 0.0 (TID 18). 1677 bytes result sent to driver
25/05/25 08:26:03 INFO TaskSetManager: Starting task 26.0 in stage 0.0 (TID 26) (desktop-fedora, executor driver, partition 26, NODE_LOCAL, 9079 bytes) 
25/05/25 08:26:03 INFO TaskSetManager: Finished task 18.0 in stage 0.0 (TID 18) in 590 ms on desktop-fedora (executor driver) (19/53)
25/05/25 08:26:03 INFO Executor: Running task 26.0 in stage 0.0 (TID 26)
25/05/25 08:26:03 INFO Executor: Finished task 17.0 in stage 0.0 (TID 17). 1677 bytes result sent to driver
25/05/25 08:26:03 INFO TaskSetManager: Starting task 27.0 in stage 0.0 (TID 27) (desktop-fedora, executor driver, partition 27, NODE_LOCAL, 9079 bytes) 
25/05/25 08:26:03 INFO Executor: Running task 27.0 in stage 0.0 (TID 27)
25/05/25 08:26:03 INFO TaskSetManager: Finished task 17.0 in stage 0.0 (TID 17) in 622 ms on desktop-fedora (executor driver) (20/53)
25/05/25 08:26:03 INFO HadoopRDD: Input split: hdfs://localhost:9000/user/giovanni/input/cleaned_pruned_used_cars_data.csv:3489660928+134217728
25/05/25 08:26:03 INFO PythonRunner: Times: total = 474, boot = -106, init = 109, finish = 471
25/05/25 08:26:03 INFO HadoopRDD: Input split: hdfs://localhost:9000/user/giovanni/input/cleaned_pruned_used_cars_data.csv:3623878656+134217728
25/05/25 08:26:03 INFO Executor: Finished task 22.0 in stage 0.0 (TID 22). 1677 bytes result sent to driver
25/05/25 08:26:03 INFO TaskSetManager: Starting task 28.0 in stage 0.0 (TID 28) (desktop-fedora, executor driver, partition 28, NODE_LOCAL, 9079 bytes) 
25/05/25 08:26:03 INFO TaskSetManager: Finished task 22.0 in stage 0.0 (TID 22) in 552 ms on desktop-fedora (executor driver) (21/53)
25/05/25 08:26:03 INFO Executor: Running task 28.0 in stage 0.0 (TID 28)
25/05/25 08:26:03 INFO PythonRunner: Times: total = 583, boot = -99, init = 102, finish = 580
25/05/25 08:26:03 INFO PythonRunner: Times: total = 460, boot = -105, init = 108, finish = 457
25/05/25 08:26:03 INFO HadoopRDD: Input split: hdfs://localhost:9000/user/giovanni/input/cleaned_pruned_used_cars_data.csv:3758096384+134217728
25/05/25 08:26:03 INFO Executor: Finished task 16.0 in stage 0.0 (TID 16). 1677 bytes result sent to driver
25/05/25 08:26:03 INFO TaskSetManager: Starting task 29.0 in stage 0.0 (TID 29) (desktop-fedora, executor driver, partition 29, NODE_LOCAL, 9079 bytes) 
25/05/25 08:26:03 INFO Executor: Finished task 23.0 in stage 0.0 (TID 23). 1677 bytes result sent to driver
25/05/25 08:26:03 INFO Executor: Running task 29.0 in stage 0.0 (TID 29)
25/05/25 08:26:03 INFO TaskSetManager: Starting task 30.0 in stage 0.0 (TID 30) (desktop-fedora, executor driver, partition 30, NODE_LOCAL, 9079 bytes) 
25/05/25 08:26:03 INFO TaskSetManager: Finished task 16.0 in stage 0.0 (TID 16) in 662 ms on desktop-fedora (executor driver) (22/53)
25/05/25 08:26:03 INFO TaskSetManager: Finished task 23.0 in stage 0.0 (TID 23) in 553 ms on desktop-fedora (executor driver) (23/53)
25/05/25 08:26:03 INFO Executor: Running task 30.0 in stage 0.0 (TID 30)
25/05/25 08:26:03 INFO HadoopRDD: Input split: hdfs://localhost:9000/user/giovanni/input/cleaned_pruned_used_cars_data.csv:3892314112+134217728
25/05/25 08:26:03 INFO HadoopRDD: Input split: hdfs://localhost:9000/user/giovanni/input/cleaned_pruned_used_cars_data.csv:4026531840+134217728
25/05/25 08:26:03 INFO PythonRunner: Times: total = 573, boot = -88, init = 91, finish = 570
25/05/25 08:26:03 INFO Executor: Finished task 20.0 in stage 0.0 (TID 20). 1677 bytes result sent to driver
25/05/25 08:26:03 INFO TaskSetManager: Starting task 31.0 in stage 0.0 (TID 31) (desktop-fedora, executor driver, partition 31, NODE_LOCAL, 9079 bytes) 
25/05/25 08:26:03 INFO TaskSetManager: Finished task 20.0 in stage 0.0 (TID 20) in 654 ms on desktop-fedora (executor driver) (24/53)
25/05/25 08:26:03 INFO Executor: Running task 31.0 in stage 0.0 (TID 31)
25/05/25 08:26:03 INFO HadoopRDD: Input split: hdfs://localhost:9000/user/giovanni/input/cleaned_pruned_used_cars_data.csv:4160749568+134217728
25/05/25 08:26:03 INFO PythonRunner: Times: total = 460, boot = -68, init = 71, finish = 457
25/05/25 08:26:03 INFO Executor: Finished task 24.0 in stage 0.0 (TID 24). 1677 bytes result sent to driver
25/05/25 08:26:03 INFO TaskSetManager: Starting task 32.0 in stage 0.0 (TID 32) (desktop-fedora, executor driver, partition 32, NODE_LOCAL, 9079 bytes) 
25/05/25 08:26:03 INFO Executor: Running task 32.0 in stage 0.0 (TID 32)
25/05/25 08:26:03 INFO TaskSetManager: Finished task 24.0 in stage 0.0 (TID 24) in 520 ms on desktop-fedora (executor driver) (25/53)
25/05/25 08:26:03 INFO HadoopRDD: Input split: hdfs://localhost:9000/user/giovanni/input/cleaned_pruned_used_cars_data.csv:4294967296+134217728
25/05/25 08:26:03 INFO PythonRunner: Times: total = 446, boot = -65, init = 69, finish = 442
25/05/25 08:26:03 INFO Executor: Finished task 28.0 in stage 0.0 (TID 28). 1677 bytes result sent to driver
25/05/25 08:26:03 INFO TaskSetManager: Starting task 33.0 in stage 0.0 (TID 33) (desktop-fedora, executor driver, partition 33, NODE_LOCAL, 9079 bytes) 
25/05/25 08:26:03 INFO TaskSetManager: Finished task 28.0 in stage 0.0 (TID 28) in 521 ms on desktop-fedora (executor driver) (26/53)
25/05/25 08:26:03 INFO Executor: Running task 33.0 in stage 0.0 (TID 33)
25/05/25 08:26:03 INFO PythonRunner: Times: total = 447, boot = -61, init = 64, finish = 444
25/05/25 08:26:03 INFO HadoopRDD: Input split: hdfs://localhost:9000/user/giovanni/input/cleaned_pruned_used_cars_data.csv:4429185024+134217728
25/05/25 08:26:03 INFO PythonRunner: Times: total = 499, boot = -30, init = 34, finish = 495
25/05/25 08:26:03 INFO Executor: Finished task 30.0 in stage 0.0 (TID 30). 1677 bytes result sent to driver
25/05/25 08:26:03 INFO TaskSetManager: Starting task 34.0 in stage 0.0 (TID 34) (desktop-fedora, executor driver, partition 34, NODE_LOCAL, 9079 bytes) 
25/05/25 08:26:03 INFO TaskSetManager: Finished task 30.0 in stage 0.0 (TID 30) in 514 ms on desktop-fedora (executor driver) (27/53)
25/05/25 08:26:03 INFO Executor: Running task 34.0 in stage 0.0 (TID 34)
25/05/25 08:26:03 INFO Executor: Finished task 26.0 in stage 0.0 (TID 26). 1720 bytes result sent to driver
25/05/25 08:26:03 INFO TaskSetManager: Starting task 35.0 in stage 0.0 (TID 35) (desktop-fedora, executor driver, partition 35, NODE_LOCAL, 9079 bytes) 
25/05/25 08:26:03 INFO HadoopRDD: Input split: hdfs://localhost:9000/user/giovanni/input/cleaned_pruned_used_cars_data.csv:4563402752+134217728
25/05/25 08:26:03 INFO Executor: Running task 35.0 in stage 0.0 (TID 35)
25/05/25 08:26:03 INFO TaskSetManager: Finished task 26.0 in stage 0.0 (TID 26) in 550 ms on desktop-fedora (executor driver) (28/53)
25/05/25 08:26:03 INFO HadoopRDD: Input split: hdfs://localhost:9000/user/giovanni/input/cleaned_pruned_used_cars_data.csv:4697620480+134217728
25/05/25 08:26:03 INFO PythonRunner: Times: total = 533, boot = -54, init = 57, finish = 530
25/05/25 08:26:03 INFO Executor: Finished task 25.0 in stage 0.0 (TID 25). 1677 bytes result sent to driver
25/05/25 08:26:03 INFO PythonRunner: Times: total = 526, boot = -38, init = 42, finish = 522
25/05/25 08:26:03 INFO TaskSetManager: Starting task 36.0 in stage 0.0 (TID 36) (desktop-fedora, executor driver, partition 36, NODE_LOCAL, 9079 bytes) 
25/05/25 08:26:03 INFO TaskSetManager: Finished task 25.0 in stage 0.0 (TID 25) in 598 ms on desktop-fedora (executor driver) (29/53)
25/05/25 08:26:03 INFO Executor: Running task 36.0 in stage 0.0 (TID 36)
25/05/25 08:26:03 INFO HadoopRDD: Input split: hdfs://localhost:9000/user/giovanni/input/cleaned_pruned_used_cars_data.csv:4831838208+134217728
25/05/25 08:26:03 INFO Executor: Finished task 27.0 in stage 0.0 (TID 27). 1677 bytes result sent to driver
25/05/25 08:26:03 INFO TaskSetManager: Starting task 37.0 in stage 0.0 (TID 37) (desktop-fedora, executor driver, partition 37, NODE_LOCAL, 9079 bytes) 
25/05/25 08:26:03 INFO TaskSetManager: Finished task 27.0 in stage 0.0 (TID 27) in 583 ms on desktop-fedora (executor driver) (30/53)
25/05/25 08:26:03 INFO Executor: Running task 37.0 in stage 0.0 (TID 37)
25/05/25 08:26:03 INFO HadoopRDD: Input split: hdfs://localhost:9000/user/giovanni/input/cleaned_pruned_used_cars_data.csv:4966055936+134217728
25/05/25 08:26:03 INFO PythonRunner: Times: total = 492, boot = -64, init = 68, finish = 488
25/05/25 08:26:03 INFO Executor: Finished task 29.0 in stage 0.0 (TID 29). 1677 bytes result sent to driver
25/05/25 08:26:03 INFO TaskSetManager: Starting task 38.0 in stage 0.0 (TID 38) (desktop-fedora, executor driver, partition 38, NODE_LOCAL, 9079 bytes) 
25/05/25 08:26:03 INFO TaskSetManager: Finished task 29.0 in stage 0.0 (TID 29) in 574 ms on desktop-fedora (executor driver) (31/53)
25/05/25 08:26:03 INFO Executor: Running task 38.0 in stage 0.0 (TID 38)
25/05/25 08:26:03 INFO HadoopRDD: Input split: hdfs://localhost:9000/user/giovanni/input/cleaned_pruned_used_cars_data.csv:5100273664+134217728
25/05/25 08:26:03 INFO PythonRunner: Times: total = 507, boot = -63, init = 68, finish = 502
25/05/25 08:26:03 INFO Executor: Finished task 31.0 in stage 0.0 (TID 31). 1677 bytes result sent to driver
25/05/25 08:26:03 INFO TaskSetManager: Starting task 39.0 in stage 0.0 (TID 39) (desktop-fedora, executor driver, partition 39, NODE_LOCAL, 9079 bytes) 
25/05/25 08:26:03 INFO Executor: Running task 39.0 in stage 0.0 (TID 39)
25/05/25 08:26:03 INFO TaskSetManager: Finished task 31.0 in stage 0.0 (TID 31) in 609 ms on desktop-fedora (executor driver) (32/53)
25/05/25 08:26:03 INFO HadoopRDD: Input split: hdfs://localhost:9000/user/giovanni/input/cleaned_pruned_used_cars_data.csv:5234491392+134217728
25/05/25 08:26:04 INFO PythonRunner: Times: total = 538, boot = -36, init = 40, finish = 534
25/05/25 08:26:04 INFO PythonRunner: Times: total = 472, boot = -36, init = 41, finish = 467
25/05/25 08:26:04 INFO Executor: Finished task 32.0 in stage 0.0 (TID 32). 1677 bytes result sent to driver
25/05/25 08:26:04 INFO TaskSetManager: Starting task 40.0 in stage 0.0 (TID 40) (desktop-fedora, executor driver, partition 40, NODE_LOCAL, 9079 bytes) 
25/05/25 08:26:04 INFO Executor: Running task 40.0 in stage 0.0 (TID 40)
25/05/25 08:26:04 INFO TaskSetManager: Finished task 32.0 in stage 0.0 (TID 32) in 627 ms on desktop-fedora (executor driver) (33/53)
25/05/25 08:26:04 INFO Executor: Finished task 37.0 in stage 0.0 (TID 37). 1677 bytes result sent to driver
25/05/25 08:26:04 INFO TaskSetManager: Starting task 41.0 in stage 0.0 (TID 41) (desktop-fedora, executor driver, partition 41, NODE_LOCAL, 9079 bytes) 
25/05/25 08:26:04 INFO TaskSetManager: Finished task 37.0 in stage 0.0 (TID 37) in 534 ms on desktop-fedora (executor driver) (34/53)
25/05/25 08:26:04 INFO Executor: Running task 41.0 in stage 0.0 (TID 41)
25/05/25 08:26:04 INFO HadoopRDD: Input split: hdfs://localhost:9000/user/giovanni/input/cleaned_pruned_used_cars_data.csv:5368709120+134217728
25/05/25 08:26:04 INFO HadoopRDD: Input split: hdfs://localhost:9000/user/giovanni/input/cleaned_pruned_used_cars_data.csv:5502926848+134217728
25/05/25 08:26:04 INFO PythonRunner: Times: total = 539, boot = -49, init = 53, finish = 535
25/05/25 08:26:04 INFO PythonRunner: Times: total = 534, boot = -51, init = 55, finish = 530
25/05/25 08:26:04 INFO PythonRunner: Times: total = 518, boot = -51, init = 54, finish = 515
25/05/25 08:26:04 INFO Executor: Finished task 33.0 in stage 0.0 (TID 33). 1677 bytes result sent to driver
25/05/25 08:26:04 INFO TaskSetManager: Starting task 42.0 in stage 0.0 (TID 42) (desktop-fedora, executor driver, partition 42, NODE_LOCAL, 9079 bytes) 
25/05/25 08:26:04 INFO TaskSetManager: Finished task 33.0 in stage 0.0 (TID 33) in 608 ms on desktop-fedora (executor driver) (35/53)
25/05/25 08:26:04 INFO Executor: Running task 42.0 in stage 0.0 (TID 42)
25/05/25 08:26:04 INFO Executor: Finished task 36.0 in stage 0.0 (TID 36). 1677 bytes result sent to driver
25/05/25 08:26:04 INFO Executor: Finished task 34.0 in stage 0.0 (TID 34). 1677 bytes result sent to driver
25/05/25 08:26:04 INFO TaskSetManager: Starting task 43.0 in stage 0.0 (TID 43) (desktop-fedora, executor driver, partition 43, NODE_LOCAL, 9079 bytes) 
25/05/25 08:26:04 INFO Executor: Running task 43.0 in stage 0.0 (TID 43)
25/05/25 08:26:04 INFO TaskSetManager: Starting task 44.0 in stage 0.0 (TID 44) (desktop-fedora, executor driver, partition 44, NODE_LOCAL, 9079 bytes) 
25/05/25 08:26:04 INFO TaskSetManager: Finished task 36.0 in stage 0.0 (TID 36) in 575 ms on desktop-fedora (executor driver) (36/53)
25/05/25 08:26:04 INFO Executor: Running task 44.0 in stage 0.0 (TID 44)
25/05/25 08:26:04 INFO TaskSetManager: Finished task 34.0 in stage 0.0 (TID 34) in 602 ms on desktop-fedora (executor driver) (37/53)
25/05/25 08:26:04 INFO HadoopRDD: Input split: hdfs://localhost:9000/user/giovanni/input/cleaned_pruned_used_cars_data.csv:5637144576+134217728
25/05/25 08:26:04 INFO HadoopRDD: Input split: hdfs://localhost:9000/user/giovanni/input/cleaned_pruned_used_cars_data.csv:5771362304+134217728
25/05/25 08:26:04 INFO HadoopRDD: Input split: hdfs://localhost:9000/user/giovanni/input/cleaned_pruned_used_cars_data.csv:5905580032+134217728
25/05/25 08:26:04 INFO PythonRunner: Times: total = 596, boot = -31, init = 35, finish = 592
25/05/25 08:26:04 INFO PythonRunner: Times: total = 558, boot = -60, init = 70, finish = 548
25/05/25 08:26:04 INFO Executor: Finished task 35.0 in stage 0.0 (TID 35). 1677 bytes result sent to driver
25/05/25 08:26:04 INFO TaskSetManager: Starting task 45.0 in stage 0.0 (TID 45) (desktop-fedora, executor driver, partition 45, NODE_LOCAL, 9079 bytes) 
25/05/25 08:26:04 INFO Executor: Running task 45.0 in stage 0.0 (TID 45)
25/05/25 08:26:04 INFO TaskSetManager: Finished task 35.0 in stage 0.0 (TID 35) in 683 ms on desktop-fedora (executor driver) (38/53)
25/05/25 08:26:04 INFO Executor: Finished task 38.0 in stage 0.0 (TID 38). 1677 bytes result sent to driver
25/05/25 08:26:04 INFO TaskSetManager: Starting task 46.0 in stage 0.0 (TID 46) (desktop-fedora, executor driver, partition 46, NODE_LOCAL, 9079 bytes) 
25/05/25 08:26:04 INFO HadoopRDD: Input split: hdfs://localhost:9000/user/giovanni/input/cleaned_pruned_used_cars_data.csv:6039797760+134217728
25/05/25 08:26:04 INFO Executor: Running task 46.0 in stage 0.0 (TID 46)
25/05/25 08:26:04 INFO TaskSetManager: Finished task 38.0 in stage 0.0 (TID 38) in 636 ms on desktop-fedora (executor driver) (39/53)
25/05/25 08:26:04 INFO HadoopRDD: Input split: hdfs://localhost:9000/user/giovanni/input/cleaned_pruned_used_cars_data.csv:6174015488+134217728
25/05/25 08:26:04 INFO PythonRunner: Times: total = 496, boot = -81, init = 87, finish = 490
25/05/25 08:26:04 INFO Executor: Finished task 39.0 in stage 0.0 (TID 39). 1677 bytes result sent to driver
25/05/25 08:26:04 INFO TaskSetManager: Starting task 47.0 in stage 0.0 (TID 47) (desktop-fedora, executor driver, partition 47, NODE_LOCAL, 9079 bytes) 
25/05/25 08:26:04 INFO Executor: Running task 47.0 in stage 0.0 (TID 47)
25/05/25 08:26:04 INFO TaskSetManager: Finished task 39.0 in stage 0.0 (TID 39) in 595 ms on desktop-fedora (executor driver) (40/53)
25/05/25 08:26:04 INFO HadoopRDD: Input split: hdfs://localhost:9000/user/giovanni/input/cleaned_pruned_used_cars_data.csv:6308233216+134217728
25/05/25 08:26:04 INFO PythonRunner: Times: total = 569, boot = -58, init = 60, finish = 567
25/05/25 08:26:04 INFO Executor: Finished task 41.0 in stage 0.0 (TID 41). 1720 bytes result sent to driver
25/05/25 08:26:04 INFO TaskSetManager: Starting task 48.0 in stage 0.0 (TID 48) (desktop-fedora, executor driver, partition 48, NODE_LOCAL, 9079 bytes) 
25/05/25 08:26:04 INFO TaskSetManager: Finished task 41.0 in stage 0.0 (TID 41) in 679 ms on desktop-fedora (executor driver) (41/53)
25/05/25 08:26:04 INFO Executor: Running task 48.0 in stage 0.0 (TID 48)
25/05/25 08:26:04 INFO HadoopRDD: Input split: hdfs://localhost:9000/user/giovanni/input/cleaned_pruned_used_cars_data.csv:6442450944+134217728
25/05/25 08:26:04 INFO PythonRunner: Times: total = 604, boot = -19, init = 22, finish = 601
25/05/25 08:26:05 INFO Executor: Finished task 42.0 in stage 0.0 (TID 42). 1677 bytes result sent to driver
25/05/25 08:26:05 INFO TaskSetManager: Starting task 49.0 in stage 0.0 (TID 49) (desktop-fedora, executor driver, partition 49, NODE_LOCAL, 9079 bytes) 
25/05/25 08:26:05 INFO Executor: Running task 49.0 in stage 0.0 (TID 49)
25/05/25 08:26:05 INFO TaskSetManager: Finished task 42.0 in stage 0.0 (TID 42) in 678 ms on desktop-fedora (executor driver) (42/53)
25/05/25 08:26:05 INFO HadoopRDD: Input split: hdfs://localhost:9000/user/giovanni/input/cleaned_pruned_used_cars_data.csv:6576668672+134217728
25/05/25 08:26:05 INFO PythonRunner: Times: total = 524, boot = -48, init = 51, finish = 521
25/05/25 08:26:05 INFO PythonRunner: Times: total = 650, boot = -28, init = 30, finish = 648
25/05/25 08:26:05 INFO Executor: Finished task 40.0 in stage 0.0 (TID 40). 1677 bytes result sent to driver
25/05/25 08:26:05 INFO Executor: Finished task 46.0 in stage 0.0 (TID 46). 1677 bytes result sent to driver
25/05/25 08:26:05 INFO TaskSetManager: Starting task 50.0 in stage 0.0 (TID 50) (desktop-fedora, executor driver, partition 50, NODE_LOCAL, 9079 bytes) 
25/05/25 08:26:05 INFO PythonRunner: Times: total = 649, boot = -37, init = 40, finish = 646
25/05/25 08:26:05 INFO TaskSetManager: Finished task 46.0 in stage 0.0 (TID 46) in 602 ms on desktop-fedora (executor driver) (43/53)
25/05/25 08:26:05 INFO Executor: Running task 50.0 in stage 0.0 (TID 50)
25/05/25 08:26:05 INFO TaskSetManager: Starting task 51.0 in stage 0.0 (TID 51) (desktop-fedora, executor driver, partition 51, NODE_LOCAL, 9079 bytes) 
25/05/25 08:26:05 INFO TaskSetManager: Finished task 40.0 in stage 0.0 (TID 40) in 726 ms on desktop-fedora (executor driver) (44/53)
25/05/25 08:26:05 INFO Executor: Running task 51.0 in stage 0.0 (TID 51)
25/05/25 08:26:05 INFO HadoopRDD: Input split: hdfs://localhost:9000/user/giovanni/input/cleaned_pruned_used_cars_data.csv:6710886400+134217728
25/05/25 08:26:05 INFO Executor: Finished task 43.0 in stage 0.0 (TID 43). 1677 bytes result sent to driver
25/05/25 08:26:05 INFO HadoopRDD: Input split: hdfs://localhost:9000/user/giovanni/input/cleaned_pruned_used_cars_data.csv:6845104128+134217728
25/05/25 08:26:05 INFO TaskSetManager: Starting task 52.0 in stage 0.0 (TID 52) (desktop-fedora, executor driver, partition 52, NODE_LOCAL, 9079 bytes) 
25/05/25 08:26:05 INFO Executor: Running task 52.0 in stage 0.0 (TID 52)
25/05/25 08:26:05 INFO PythonRunner: Times: total = 560, boot = -54, init = 57, finish = 557
25/05/25 08:26:05 INFO TaskSetManager: Finished task 43.0 in stage 0.0 (TID 43) in 711 ms on desktop-fedora (executor driver) (45/53)
25/05/25 08:26:05 INFO HadoopRDD: Input split: hdfs://localhost:9000/user/giovanni/input/cleaned_pruned_used_cars_data.csv:6979321856+102704993
25/05/25 08:26:05 INFO Executor: Finished task 45.0 in stage 0.0 (TID 45). 1677 bytes result sent to driver
25/05/25 08:26:05 INFO TaskSetManager: Finished task 45.0 in stage 0.0 (TID 45) in 639 ms on desktop-fedora (executor driver) (46/53)
25/05/25 08:26:05 INFO PythonRunner: Times: total = 675, boot = -37, init = 40, finish = 672
25/05/25 08:26:05 INFO Executor: Finished task 44.0 in stage 0.0 (TID 44). 1677 bytes result sent to driver
25/05/25 08:26:05 INFO TaskSetManager: Finished task 44.0 in stage 0.0 (TID 44) in 739 ms on desktop-fedora (executor driver) (47/53)
25/05/25 08:26:05 INFO PythonRunner: Times: total = 560, boot = -104, init = 107, finish = 557
25/05/25 08:26:05 INFO Executor: Finished task 47.0 in stage 0.0 (TID 47). 1677 bytes result sent to driver
25/05/25 08:26:05 INFO TaskSetManager: Finished task 47.0 in stage 0.0 (TID 47) in 691 ms on desktop-fedora (executor driver) (48/53)
25/05/25 08:26:05 INFO PythonRunner: Times: total = 304, boot = -40, init = 42, finish = 302
25/05/25 08:26:05 INFO PythonRunner: Times: total = 336, boot = -47, init = 49, finish = 334
25/05/25 08:26:05 INFO Executor: Finished task 52.0 in stage 0.0 (TID 52). 1677 bytes result sent to driver
25/05/25 08:26:05 INFO TaskSetManager: Finished task 52.0 in stage 0.0 (TID 52) in 361 ms on desktop-fedora (executor driver) (49/53)
25/05/25 08:26:05 INFO Executor: Finished task 51.0 in stage 0.0 (TID 51). 1677 bytes result sent to driver
25/05/25 08:26:05 INFO TaskSetManager: Finished task 51.0 in stage 0.0 (TID 51) in 377 ms on desktop-fedora (executor driver) (50/53)
25/05/25 08:26:05 INFO PythonRunner: Times: total = 369, boot = -47, init = 50, finish = 366
25/05/25 08:26:05 INFO Executor: Finished task 49.0 in stage 0.0 (TID 49). 1677 bytes result sent to driver
25/05/25 08:26:05 INFO TaskSetManager: Finished task 49.0 in stage 0.0 (TID 49) in 405 ms on desktop-fedora (executor driver) (51/53)
25/05/25 08:26:05 INFO PythonRunner: Times: total = 435, boot = -83, init = 85, finish = 433
25/05/25 08:26:05 INFO Executor: Finished task 48.0 in stage 0.0 (TID 48). 1677 bytes result sent to driver
25/05/25 08:26:05 INFO TaskSetManager: Finished task 48.0 in stage 0.0 (TID 48) in 476 ms on desktop-fedora (executor driver) (52/53)
25/05/25 08:26:05 INFO PythonRunner: Times: total = 417, boot = -49, init = 51, finish = 415
25/05/25 08:26:05 INFO Executor: Finished task 50.0 in stage 0.0 (TID 50). 1677 bytes result sent to driver
25/05/25 08:26:05 INFO TaskSetManager: Finished task 50.0 in stage 0.0 (TID 50) in 460 ms on desktop-fedora (executor driver) (53/53)
25/05/25 08:26:05 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/05/25 08:26:05 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /home/giovanni/Projects/big-data/progetto/task_1/spark-core/spark-job.py:55) finished in 4.960 s
25/05/25 08:26:05 INFO DAGScheduler: looking for newly runnable stages
25/05/25 08:26:05 INFO DAGScheduler: running: Set()
25/05/25 08:26:05 INFO DAGScheduler: waiting: Set(ResultStage 1)
25/05/25 08:26:05 INFO DAGScheduler: failed: Set()
25/05/25 08:26:05 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[8] at saveAsTextFile at NativeMethodAccessorImpl.java:0), which has no missing parents
25/05/25 08:26:05 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 111.2 KiB, free 434.0 MiB)
25/05/25 08:26:05 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 42.8 KiB, free 434.0 MiB)
25/05/25 08:26:05 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on desktop-fedora:37729 (size: 42.8 KiB, free: 434.3 MiB)
25/05/25 08:26:05 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1585
25/05/25 08:26:05 INFO DAGScheduler: Submitting 53 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at saveAsTextFile at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
25/05/25 08:26:05 INFO TaskSchedulerImpl: Adding task set 1.0 with 53 tasks resource profile 0
25/05/25 08:26:05 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 53) (desktop-fedora, executor driver, partition 0, NODE_LOCAL, 8817 bytes) 
25/05/25 08:26:05 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 54) (desktop-fedora, executor driver, partition 1, NODE_LOCAL, 8817 bytes) 
25/05/25 08:26:05 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 55) (desktop-fedora, executor driver, partition 2, NODE_LOCAL, 8817 bytes) 
25/05/25 08:26:05 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 56) (desktop-fedora, executor driver, partition 3, NODE_LOCAL, 8817 bytes) 
25/05/25 08:26:05 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 57) (desktop-fedora, executor driver, partition 4, NODE_LOCAL, 8817 bytes) 
25/05/25 08:26:05 INFO TaskSetManager: Starting task 5.0 in stage 1.0 (TID 58) (desktop-fedora, executor driver, partition 5, NODE_LOCAL, 8817 bytes) 
25/05/25 08:26:05 INFO TaskSetManager: Starting task 6.0 in stage 1.0 (TID 59) (desktop-fedora, executor driver, partition 6, NODE_LOCAL, 8817 bytes) 
25/05/25 08:26:05 INFO TaskSetManager: Starting task 7.0 in stage 1.0 (TID 60) (desktop-fedora, executor driver, partition 7, NODE_LOCAL, 8817 bytes) 
25/05/25 08:26:05 INFO Executor: Running task 0.0 in stage 1.0 (TID 53)
25/05/25 08:26:05 INFO Executor: Running task 4.0 in stage 1.0 (TID 57)
25/05/25 08:26:05 INFO Executor: Running task 1.0 in stage 1.0 (TID 54)
25/05/25 08:26:05 INFO Executor: Running task 3.0 in stage 1.0 (TID 56)
25/05/25 08:26:05 INFO Executor: Running task 2.0 in stage 1.0 (TID 55)
25/05/25 08:26:05 INFO Executor: Running task 5.0 in stage 1.0 (TID 58)
25/05/25 08:26:05 INFO Executor: Running task 7.0 in stage 1.0 (TID 60)
25/05/25 08:26:05 INFO Executor: Running task 6.0 in stage 1.0 (TID 59)
25/05/25 08:26:05 INFO ShuffleBlockFetcherIterator: Getting 53 (28.2 KiB) non-empty blocks including 53 (28.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/05/25 08:26:05 INFO ShuffleBlockFetcherIterator: Getting 53 (35.1 KiB) non-empty blocks including 53 (35.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/05/25 08:26:05 INFO ShuffleBlockFetcherIterator: Getting 53 (43.1 KiB) non-empty blocks including 53 (43.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/05/25 08:26:05 INFO ShuffleBlockFetcherIterator: Getting 53 (28.3 KiB) non-empty blocks including 53 (28.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/05/25 08:26:05 INFO ShuffleBlockFetcherIterator: Getting 53 (41.5 KiB) non-empty blocks including 53 (41.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/05/25 08:26:05 INFO ShuffleBlockFetcherIterator: Getting 53 (24.9 KiB) non-empty blocks including 53 (24.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/05/25 08:26:05 INFO ShuffleBlockFetcherIterator: Getting 53 (41.8 KiB) non-empty blocks including 53 (41.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/05/25 08:26:05 INFO ShuffleBlockFetcherIterator: Getting 53 (22.1 KiB) non-empty blocks including 53 (22.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/05/25 08:26:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
25/05/25 08:26:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
25/05/25 08:26:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
25/05/25 08:26:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
25/05/25 08:26:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
25/05/25 08:26:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
25/05/25 08:26:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
25/05/25 08:26:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
25/05/25 08:26:05 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
25/05/25 08:26:05 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
25/05/25 08:26:05 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
25/05/25 08:26:05 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
25/05/25 08:26:05 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
25/05/25 08:26:05 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
25/05/25 08:26:05 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
25/05/25 08:26:05 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
25/05/25 08:26:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/05/25 08:26:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/05/25 08:26:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/05/25 08:26:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/05/25 08:26:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/05/25 08:26:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/05/25 08:26:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/05/25 08:26:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/05/25 08:26:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/05/25 08:26:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/05/25 08:26:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/05/25 08:26:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/05/25 08:26:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/05/25 08:26:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/05/25 08:26:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/05/25 08:26:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/05/25 08:26:05 INFO PythonRunner: Times: total = 43, boot = -443, init = 485, finish = 1
25/05/25 08:26:05 INFO PythonRunner: Times: total = 42, boot = -113, init = 154, finish = 1
25/05/25 08:26:05 INFO PythonRunner: Times: total = 42, boot = -182, init = 223, finish = 1
25/05/25 08:26:05 INFO PythonRunner: Times: total = 43, boot = -558, init = 600, finish = 1
25/05/25 08:26:05 INFO PythonRunner: Times: total = 44, boot = -143, init = 185, finish = 2
25/05/25 08:26:05 INFO PythonRunner: Times: total = 45, boot = -541, init = 584, finish = 2
25/05/25 08:26:05 INFO PythonRunner: Times: total = 45, boot = -190, init = 234, finish = 1
25/05/25 08:26:05 INFO PythonRunner: Times: total = 45, boot = -212, init = 256, finish = 1
25/05/25 08:26:05 INFO FileOutputCommitter: Saved output of task 'attempt_202505250826006785974358318424464_0008_m_000002_0' to hdfs://localhost:9000/user/giovanni/output/spark_cleaned_pruned_used_cars_data_result/_temporary/0/task_202505250826006785974358318424464_0008_m_000002
25/05/25 08:26:05 INFO FileOutputCommitter: Saved output of task 'attempt_202505250826006785974358318424464_0008_m_000005_0' to hdfs://localhost:9000/user/giovanni/output/spark_cleaned_pruned_used_cars_data_result/_temporary/0/task_202505250826006785974358318424464_0008_m_000005
25/05/25 08:26:05 INFO FileOutputCommitter: Saved output of task 'attempt_202505250826006785974358318424464_0008_m_000001_0' to hdfs://localhost:9000/user/giovanni/output/spark_cleaned_pruned_used_cars_data_result/_temporary/0/task_202505250826006785974358318424464_0008_m_000001
25/05/25 08:26:05 INFO FileOutputCommitter: Saved output of task 'attempt_202505250826006785974358318424464_0008_m_000007_0' to hdfs://localhost:9000/user/giovanni/output/spark_cleaned_pruned_used_cars_data_result/_temporary/0/task_202505250826006785974358318424464_0008_m_000007
25/05/25 08:26:05 INFO FileOutputCommitter: Saved output of task 'attempt_202505250826006785974358318424464_0008_m_000004_0' to hdfs://localhost:9000/user/giovanni/output/spark_cleaned_pruned_used_cars_data_result/_temporary/0/task_202505250826006785974358318424464_0008_m_000004
25/05/25 08:26:05 INFO SparkHadoopMapRedUtil: attempt_202505250826006785974358318424464_0008_m_000002_0: Committed. Elapsed time: 3 ms.
25/05/25 08:26:05 INFO SparkHadoopMapRedUtil: attempt_202505250826006785974358318424464_0008_m_000001_0: Committed. Elapsed time: 4 ms.
25/05/25 08:26:05 INFO SparkHadoopMapRedUtil: attempt_202505250826006785974358318424464_0008_m_000005_0: Committed. Elapsed time: 3 ms.
25/05/25 08:26:05 INFO SparkHadoopMapRedUtil: attempt_202505250826006785974358318424464_0008_m_000004_0: Committed. Elapsed time: 4 ms.
25/05/25 08:26:05 INFO SparkHadoopMapRedUtil: attempt_202505250826006785974358318424464_0008_m_000007_0: Committed. Elapsed time: 4 ms.
25/05/25 08:26:05 INFO Executor: Finished task 2.0 in stage 1.0 (TID 55). 2394 bytes result sent to driver
25/05/25 08:26:05 INFO Executor: Finished task 4.0 in stage 1.0 (TID 57). 2394 bytes result sent to driver
25/05/25 08:26:05 INFO Executor: Finished task 1.0 in stage 1.0 (TID 54). 2394 bytes result sent to driver
25/05/25 08:26:05 INFO Executor: Finished task 5.0 in stage 1.0 (TID 58). 2394 bytes result sent to driver
25/05/25 08:26:05 INFO Executor: Finished task 7.0 in stage 1.0 (TID 60). 2394 bytes result sent to driver
25/05/25 08:26:05 INFO TaskSetManager: Starting task 8.0 in stage 1.0 (TID 61) (desktop-fedora, executor driver, partition 8, NODE_LOCAL, 8817 bytes) 
25/05/25 08:26:05 INFO Executor: Running task 8.0 in stage 1.0 (TID 61)
25/05/25 08:26:05 INFO TaskSetManager: Starting task 9.0 in stage 1.0 (TID 62) (desktop-fedora, executor driver, partition 9, NODE_LOCAL, 8817 bytes) 
25/05/25 08:26:05 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 55) in 147 ms on desktop-fedora (executor driver) (1/53)
25/05/25 08:26:05 INFO Executor: Running task 9.0 in stage 1.0 (TID 62)
25/05/25 08:26:05 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 54) in 147 ms on desktop-fedora (executor driver) (2/53)
25/05/25 08:26:05 INFO TaskSetManager: Starting task 10.0 in stage 1.0 (TID 63) (desktop-fedora, executor driver, partition 10, NODE_LOCAL, 8817 bytes) 
25/05/25 08:26:05 INFO Executor: Running task 10.0 in stage 1.0 (TID 63)
25/05/25 08:26:05 INFO TaskSetManager: Starting task 11.0 in stage 1.0 (TID 64) (desktop-fedora, executor driver, partition 11, NODE_LOCAL, 8817 bytes) 
25/05/25 08:26:05 INFO TaskSetManager: Finished task 5.0 in stage 1.0 (TID 58) in 148 ms on desktop-fedora (executor driver) (3/53)
25/05/25 08:26:05 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 57) in 148 ms on desktop-fedora (executor driver) (4/53)
25/05/25 08:26:05 INFO Executor: Running task 11.0 in stage 1.0 (TID 64)
25/05/25 08:26:05 INFO TaskSetManager: Starting task 12.0 in stage 1.0 (TID 65) (desktop-fedora, executor driver, partition 12, NODE_LOCAL, 8817 bytes) 
25/05/25 08:26:05 INFO TaskSetManager: Finished task 7.0 in stage 1.0 (TID 60) in 148 ms on desktop-fedora (executor driver) (5/53)
25/05/25 08:26:05 INFO Executor: Running task 12.0 in stage 1.0 (TID 65)
25/05/25 08:26:05 INFO ShuffleBlockFetcherIterator: Getting 53 (27.3 KiB) non-empty blocks including 53 (27.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/05/25 08:26:05 INFO ShuffleBlockFetcherIterator: Getting 53 (38.0 KiB) non-empty blocks including 53 (38.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/05/25 08:26:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/05/25 08:26:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/05/25 08:26:05 INFO ShuffleBlockFetcherIterator: Getting 53 (29.0 KiB) non-empty blocks including 53 (29.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/05/25 08:26:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/05/25 08:26:05 INFO ShuffleBlockFetcherIterator: Getting 53 (30.5 KiB) non-empty blocks including 53 (30.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/05/25 08:26:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/05/25 08:26:05 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
25/05/25 08:26:05 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
25/05/25 08:26:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/05/25 08:26:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/05/25 08:26:05 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
25/05/25 08:26:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/05/25 08:26:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/05/25 08:26:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/05/25 08:26:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/05/25 08:26:05 INFO ShuffleBlockFetcherIterator: Getting 53 (43.2 KiB) non-empty blocks including 53 (43.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/05/25 08:26:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
25/05/25 08:26:05 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
25/05/25 08:26:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/05/25 08:26:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/05/25 08:26:05 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
25/05/25 08:26:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/05/25 08:26:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/05/25 08:26:05 INFO PythonRunner: Times: total = 42, boot = -40, init = 82, finish = 0
25/05/25 08:26:05 INFO PythonRunner: Times: total = 43, boot = -40, init = 82, finish = 1
25/05/25 08:26:05 INFO PythonRunner: Times: total = 44, boot = -43, init = 85, finish = 2
25/05/25 08:26:05 INFO PythonRunner: Times: total = 45, boot = -43, init = 86, finish = 2
25/05/25 08:26:05 INFO PythonRunner: Times: total = 45, boot = -44, init = 87, finish = 2
25/05/25 08:26:05 INFO FileOutputCommitter: Saved output of task 'attempt_202505250826006785974358318424464_0008_m_000010_0' to hdfs://localhost:9000/user/giovanni/output/spark_cleaned_pruned_used_cars_data_result/_temporary/0/task_202505250826006785974358318424464_0008_m_000010
25/05/25 08:26:05 INFO SparkHadoopMapRedUtil: attempt_202505250826006785974358318424464_0008_m_000010_0: Committed. Elapsed time: 4 ms.
25/05/25 08:26:05 INFO Executor: Finished task 10.0 in stage 1.0 (TID 63). 2351 bytes result sent to driver
25/05/25 08:26:05 INFO TaskSetManager: Starting task 13.0 in stage 1.0 (TID 66) (desktop-fedora, executor driver, partition 13, NODE_LOCAL, 8817 bytes) 
25/05/25 08:26:05 INFO Executor: Running task 13.0 in stage 1.0 (TID 66)
25/05/25 08:26:05 INFO TaskSetManager: Finished task 10.0 in stage 1.0 (TID 63) in 73 ms on desktop-fedora (executor driver) (6/53)
25/05/25 08:26:05 INFO ShuffleBlockFetcherIterator: Getting 53 (29.7 KiB) non-empty blocks including 53 (29.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/05/25 08:26:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/05/25 08:26:05 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
25/05/25 08:26:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/05/25 08:26:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/05/25 08:26:05 INFO PythonRunner: Times: total = 43, boot = -107, init = 149, finish = 1
25/05/25 08:26:05 INFO FileOutputCommitter: Saved output of task 'attempt_202505250826006785974358318424464_0008_m_000013_0' to hdfs://localhost:9000/user/giovanni/output/spark_cleaned_pruned_used_cars_data_result/_temporary/0/task_202505250826006785974358318424464_0008_m_000013
25/05/25 08:26:05 INFO SparkHadoopMapRedUtil: attempt_202505250826006785974358318424464_0008_m_000013_0: Committed. Elapsed time: 1 ms.
25/05/25 08:26:05 INFO Executor: Finished task 13.0 in stage 1.0 (TID 66). 2351 bytes result sent to driver
25/05/25 08:26:05 INFO TaskSetManager: Starting task 14.0 in stage 1.0 (TID 67) (desktop-fedora, executor driver, partition 14, NODE_LOCAL, 8817 bytes) 
25/05/25 08:26:05 INFO TaskSetManager: Finished task 13.0 in stage 1.0 (TID 66) in 59 ms on desktop-fedora (executor driver) (7/53)
25/05/25 08:26:05 INFO Executor: Running task 14.0 in stage 1.0 (TID 67)
25/05/25 08:26:05 INFO ShuffleBlockFetcherIterator: Getting 53 (45.4 KiB) non-empty blocks including 53 (45.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/05/25 08:26:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/05/25 08:26:05 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
25/05/25 08:26:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/05/25 08:26:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/05/25 08:26:05 INFO PythonRunner: Times: total = 4, boot = -166, init = 168, finish = 2
25/05/25 08:26:05 INFO FileOutputCommitter: Saved output of task 'attempt_202505250826006785974358318424464_0008_m_000014_0' to hdfs://localhost:9000/user/giovanni/output/spark_cleaned_pruned_used_cars_data_result/_temporary/0/task_202505250826006785974358318424464_0008_m_000014
25/05/25 08:26:05 INFO SparkHadoopMapRedUtil: attempt_202505250826006785974358318424464_0008_m_000014_0: Committed. Elapsed time: 1 ms.
25/05/25 08:26:05 INFO Executor: Finished task 14.0 in stage 1.0 (TID 67). 2351 bytes result sent to driver
25/05/25 08:26:05 INFO TaskSetManager: Starting task 15.0 in stage 1.0 (TID 68) (desktop-fedora, executor driver, partition 15, NODE_LOCAL, 8817 bytes) 
25/05/25 08:26:05 INFO TaskSetManager: Finished task 14.0 in stage 1.0 (TID 67) in 21 ms on desktop-fedora (executor driver) (8/53)
25/05/25 08:26:05 INFO Executor: Running task 15.0 in stage 1.0 (TID 68)
25/05/25 08:26:05 INFO ShuffleBlockFetcherIterator: Getting 53 (35.6 KiB) non-empty blocks including 53 (35.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/05/25 08:26:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/05/25 08:26:05 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
25/05/25 08:26:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/05/25 08:26:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/05/25 08:26:05 INFO PythonRunner: Times: total = 44, boot = -189, init = 231, finish = 2
25/05/25 08:26:05 INFO FileOutputCommitter: Saved output of task 'attempt_202505250826006785974358318424464_0008_m_000015_0' to hdfs://localhost:9000/user/giovanni/output/spark_cleaned_pruned_used_cars_data_result/_temporary/0/task_202505250826006785974358318424464_0008_m_000015
25/05/25 08:26:05 INFO SparkHadoopMapRedUtil: attempt_202505250826006785974358318424464_0008_m_000015_0: Committed. Elapsed time: 1 ms.
25/05/25 08:26:05 INFO Executor: Finished task 15.0 in stage 1.0 (TID 68). 2351 bytes result sent to driver
25/05/25 08:26:05 INFO TaskSetManager: Starting task 16.0 in stage 1.0 (TID 69) (desktop-fedora, executor driver, partition 16, NODE_LOCAL, 8817 bytes) 
25/05/25 08:26:05 INFO Executor: Running task 16.0 in stage 1.0 (TID 69)
25/05/25 08:26:05 INFO TaskSetManager: Finished task 15.0 in stage 1.0 (TID 68) in 62 ms on desktop-fedora (executor driver) (9/53)
25/05/25 08:26:05 INFO ShuffleBlockFetcherIterator: Getting 53 (39.9 KiB) non-empty blocks including 53 (39.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/05/25 08:26:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/05/25 08:26:05 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
25/05/25 08:26:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/05/25 08:26:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/05/25 08:26:05 INFO PythonRunner: Times: total = 43, boot = -148, init = 189, finish = 2
25/05/25 08:26:05 INFO FileOutputCommitter: Saved output of task 'attempt_202505250826006785974358318424464_0008_m_000016_0' to hdfs://localhost:9000/user/giovanni/output/spark_cleaned_pruned_used_cars_data_result/_temporary/0/task_202505250826006785974358318424464_0008_m_000016
25/05/25 08:26:05 INFO SparkHadoopMapRedUtil: attempt_202505250826006785974358318424464_0008_m_000016_0: Committed. Elapsed time: 1 ms.
25/05/25 08:26:05 INFO Executor: Finished task 16.0 in stage 1.0 (TID 69). 2351 bytes result sent to driver
25/05/25 08:26:05 INFO TaskSetManager: Starting task 17.0 in stage 1.0 (TID 70) (desktop-fedora, executor driver, partition 17, NODE_LOCAL, 8817 bytes) 
25/05/25 08:26:05 INFO Executor: Running task 17.0 in stage 1.0 (TID 70)
25/05/25 08:26:05 INFO TaskSetManager: Finished task 16.0 in stage 1.0 (TID 69) in 58 ms on desktop-fedora (executor driver) (10/53)
25/05/25 08:26:05 INFO ShuffleBlockFetcherIterator: Getting 53 (50.7 KiB) non-empty blocks including 53 (50.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/05/25 08:26:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/05/25 08:26:05 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
25/05/25 08:26:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/05/25 08:26:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/05/25 08:26:05 INFO PythonRunner: Times: total = 5, boot = -205, init = 208, finish = 2
25/05/25 08:26:05 INFO FileOutputCommitter: Saved output of task 'attempt_202505250826006785974358318424464_0008_m_000017_0' to hdfs://localhost:9000/user/giovanni/output/spark_cleaned_pruned_used_cars_data_result/_temporary/0/task_202505250826006785974358318424464_0008_m_000017
25/05/25 08:26:05 INFO SparkHadoopMapRedUtil: attempt_202505250826006785974358318424464_0008_m_000017_0: Committed. Elapsed time: 1 ms.
25/05/25 08:26:05 INFO Executor: Finished task 17.0 in stage 1.0 (TID 70). 2351 bytes result sent to driver
25/05/25 08:26:05 INFO TaskSetManager: Starting task 18.0 in stage 1.0 (TID 71) (desktop-fedora, executor driver, partition 18, NODE_LOCAL, 8817 bytes) 
25/05/25 08:26:05 INFO TaskSetManager: Finished task 17.0 in stage 1.0 (TID 70) in 21 ms on desktop-fedora (executor driver) (11/53)
25/05/25 08:26:05 INFO Executor: Running task 18.0 in stage 1.0 (TID 71)
25/05/25 08:26:05 INFO ShuffleBlockFetcherIterator: Getting 53 (36.5 KiB) non-empty blocks including 53 (36.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/05/25 08:26:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/05/25 08:26:05 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
25/05/25 08:26:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/05/25 08:26:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/05/25 08:26:06 INFO PythonRunner: Times: total = 43, boot = -227, init = 269, finish = 1
25/05/25 08:26:06 INFO FileOutputCommitter: Saved output of task 'attempt_202505250826006785974358318424464_0008_m_000003_0' to hdfs://localhost:9000/user/giovanni/output/spark_cleaned_pruned_used_cars_data_result/_temporary/0/task_202505250826006785974358318424464_0008_m_000003
25/05/25 08:26:06 INFO SparkHadoopMapRedUtil: attempt_202505250826006785974358318424464_0008_m_000003_0: Committed. Elapsed time: 1 ms.
25/05/25 08:26:06 INFO FileOutputCommitter: Saved output of task 'attempt_202505250826006785974358318424464_0008_m_000000_0' to hdfs://localhost:9000/user/giovanni/output/spark_cleaned_pruned_used_cars_data_result/_temporary/0/task_202505250826006785974358318424464_0008_m_000000
25/05/25 08:26:06 INFO SparkHadoopMapRedUtil: attempt_202505250826006785974358318424464_0008_m_000000_0: Committed. Elapsed time: 1 ms.
25/05/25 08:26:06 INFO FileOutputCommitter: Saved output of task 'attempt_202505250826006785974358318424464_0008_m_000006_0' to hdfs://localhost:9000/user/giovanni/output/spark_cleaned_pruned_used_cars_data_result/_temporary/0/task_202505250826006785974358318424464_0008_m_000006
25/05/25 08:26:06 INFO SparkHadoopMapRedUtil: attempt_202505250826006785974358318424464_0008_m_000006_0: Committed. Elapsed time: 1 ms.
25/05/25 08:26:06 INFO Executor: Finished task 3.0 in stage 1.0 (TID 56). 2351 bytes result sent to driver
25/05/25 08:26:06 INFO Executor: Finished task 6.0 in stage 1.0 (TID 59). 2351 bytes result sent to driver
25/05/25 08:26:06 INFO Executor: Finished task 0.0 in stage 1.0 (TID 53). 2351 bytes result sent to driver
25/05/25 08:26:06 INFO TaskSetManager: Starting task 19.0 in stage 1.0 (TID 72) (desktop-fedora, executor driver, partition 19, NODE_LOCAL, 8817 bytes) 
25/05/25 08:26:06 INFO Executor: Running task 19.0 in stage 1.0 (TID 72)
25/05/25 08:26:06 INFO TaskSetManager: Starting task 20.0 in stage 1.0 (TID 73) (desktop-fedora, executor driver, partition 20, NODE_LOCAL, 8817 bytes) 
25/05/25 08:26:06 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 56) in 540 ms on desktop-fedora (executor driver) (12/53)
25/05/25 08:26:06 INFO Executor: Running task 20.0 in stage 1.0 (TID 73)
25/05/25 08:26:06 INFO TaskSetManager: Finished task 6.0 in stage 1.0 (TID 59) in 540 ms on desktop-fedora (executor driver) (13/53)
25/05/25 08:26:06 INFO TaskSetManager: Starting task 21.0 in stage 1.0 (TID 74) (desktop-fedora, executor driver, partition 21, NODE_LOCAL, 8817 bytes) 
25/05/25 08:26:06 INFO Executor: Running task 21.0 in stage 1.0 (TID 74)
25/05/25 08:26:06 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 53) in 542 ms on desktop-fedora (executor driver) (14/53)
25/05/25 08:26:06 INFO ShuffleBlockFetcherIterator: Getting 53 (20.3 KiB) non-empty blocks including 53 (20.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/05/25 08:26:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/05/25 08:26:06 INFO ShuffleBlockFetcherIterator: Getting 53 (25.7 KiB) non-empty blocks including 53 (25.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/05/25 08:26:06 INFO ShuffleBlockFetcherIterator: Getting 53 (38.2 KiB) non-empty blocks including 53 (38.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/05/25 08:26:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/05/25 08:26:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/05/25 08:26:06 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
25/05/25 08:26:06 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
25/05/25 08:26:06 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
25/05/25 08:26:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/05/25 08:26:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/05/25 08:26:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/05/25 08:26:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/05/25 08:26:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/05/25 08:26:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/05/25 08:26:06 INFO PythonRunner: Times: total = 42, boot = -271, init = 313, finish = 0
25/05/25 08:26:06 INFO PythonRunner: Times: total = 43, boot = -325, init = 367, finish = 1
25/05/25 08:26:06 INFO PythonRunner: Times: total = 44, boot = -324, init = 366, finish = 2
25/05/25 08:26:06 INFO FileOutputCommitter: Saved output of task 'attempt_202505250826006785974358318424464_0008_m_000009_0' to hdfs://localhost:9000/user/giovanni/output/spark_cleaned_pruned_used_cars_data_result/_temporary/0/task_202505250826006785974358318424464_0008_m_000009
25/05/25 08:26:06 INFO SparkHadoopMapRedUtil: attempt_202505250826006785974358318424464_0008_m_000009_0: Committed. Elapsed time: 1 ms.
25/05/25 08:26:06 INFO FileOutputCommitter: Saved output of task 'attempt_202505250826006785974358318424464_0008_m_000012_0' to hdfs://localhost:9000/user/giovanni/output/spark_cleaned_pruned_used_cars_data_result/_temporary/0/task_202505250826006785974358318424464_0008_m_000012
25/05/25 08:26:06 INFO SparkHadoopMapRedUtil: attempt_202505250826006785974358318424464_0008_m_000012_0: Committed. Elapsed time: 1 ms.
25/05/25 08:26:06 INFO Executor: Finished task 9.0 in stage 1.0 (TID 62). 2351 bytes result sent to driver
25/05/25 08:26:06 INFO Executor: Finished task 12.0 in stage 1.0 (TID 65). 2351 bytes result sent to driver
25/05/25 08:26:06 INFO TaskSetManager: Starting task 22.0 in stage 1.0 (TID 75) (desktop-fedora, executor driver, partition 22, NODE_LOCAL, 8817 bytes) 
25/05/25 08:26:06 INFO TaskSetManager: Finished task 9.0 in stage 1.0 (TID 62) in 467 ms on desktop-fedora (executor driver) (15/53)
25/05/25 08:26:06 INFO Executor: Running task 22.0 in stage 1.0 (TID 75)
25/05/25 08:26:06 INFO TaskSetManager: Starting task 23.0 in stage 1.0 (TID 76) (desktop-fedora, executor driver, partition 23, NODE_LOCAL, 8817 bytes) 
25/05/25 08:26:06 INFO Executor: Running task 23.0 in stage 1.0 (TID 76)
25/05/25 08:26:06 INFO TaskSetManager: Finished task 12.0 in stage 1.0 (TID 65) in 467 ms on desktop-fedora (executor driver) (16/53)
25/05/25 08:26:06 INFO ShuffleBlockFetcherIterator: Getting 53 (28.5 KiB) non-empty blocks including 53 (28.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/05/25 08:26:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/05/25 08:26:06 INFO ShuffleBlockFetcherIterator: Getting 53 (32.2 KiB) non-empty blocks including 53 (32.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/05/25 08:26:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/05/25 08:26:06 INFO FileOutputCommitter: Saved output of task 'attempt_202505250826006785974358318424464_0008_m_000011_0' to hdfs://localhost:9000/user/giovanni/output/spark_cleaned_pruned_used_cars_data_result/_temporary/0/task_202505250826006785974358318424464_0008_m_000011
25/05/25 08:26:06 INFO SparkHadoopMapRedUtil: attempt_202505250826006785974358318424464_0008_m_000011_0: Committed. Elapsed time: 1 ms.
25/05/25 08:26:06 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
25/05/25 08:26:06 INFO FileOutputCommitter: Saved output of task 'attempt_202505250826006785974358318424464_0008_m_000008_0' to hdfs://localhost:9000/user/giovanni/output/spark_cleaned_pruned_used_cars_data_result/_temporary/0/task_202505250826006785974358318424464_0008_m_000008
25/05/25 08:26:06 INFO SparkHadoopMapRedUtil: attempt_202505250826006785974358318424464_0008_m_000008_0: Committed. Elapsed time: 1 ms.
25/05/25 08:26:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/05/25 08:26:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/05/25 08:26:06 INFO Executor: Finished task 8.0 in stage 1.0 (TID 61). 2351 bytes result sent to driver
25/05/25 08:26:06 INFO Executor: Finished task 11.0 in stage 1.0 (TID 64). 2351 bytes result sent to driver
25/05/25 08:26:06 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
25/05/25 08:26:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/05/25 08:26:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/05/25 08:26:06 INFO TaskSetManager: Starting task 24.0 in stage 1.0 (TID 77) (desktop-fedora, executor driver, partition 24, NODE_LOCAL, 8817 bytes) 
25/05/25 08:26:06 INFO Executor: Running task 24.0 in stage 1.0 (TID 77)
25/05/25 08:26:06 INFO TaskSetManager: Starting task 25.0 in stage 1.0 (TID 78) (desktop-fedora, executor driver, partition 25, NODE_LOCAL, 8817 bytes) 
25/05/25 08:26:06 INFO TaskSetManager: Finished task 8.0 in stage 1.0 (TID 61) in 476 ms on desktop-fedora (executor driver) (17/53)
25/05/25 08:26:06 INFO Executor: Running task 25.0 in stage 1.0 (TID 78)
25/05/25 08:26:06 INFO TaskSetManager: Finished task 11.0 in stage 1.0 (TID 64) in 475 ms on desktop-fedora (executor driver) (18/53)
25/05/25 08:26:06 INFO ShuffleBlockFetcherIterator: Getting 53 (33.6 KiB) non-empty blocks including 53 (33.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/05/25 08:26:06 INFO ShuffleBlockFetcherIterator: Getting 53 (38.4 KiB) non-empty blocks including 53 (38.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/05/25 08:26:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/05/25 08:26:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/05/25 08:26:06 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
25/05/25 08:26:06 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
25/05/25 08:26:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/05/25 08:26:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/05/25 08:26:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/05/25 08:26:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/05/25 08:26:06 INFO PythonRunner: Times: total = 43, boot = -323, init = 365, finish = 1
25/05/25 08:26:06 INFO PythonRunner: Times: total = 42, boot = -262, init = 303, finish = 1
25/05/25 08:26:06 INFO PythonRunner: Times: total = 43, boot = -191, init = 233, finish = 1
25/05/25 08:26:06 INFO PythonRunner: Times: total = 44, boot = -211, init = 253, finish = 2
25/05/25 08:26:06 INFO FileOutputCommitter: Saved output of task 'attempt_202505250826006785974358318424464_0008_m_000024_0' to hdfs://localhost:9000/user/giovanni/output/spark_cleaned_pruned_used_cars_data_result/_temporary/0/task_202505250826006785974358318424464_0008_m_000024
25/05/25 08:26:06 INFO SparkHadoopMapRedUtil: attempt_202505250826006785974358318424464_0008_m_000024_0: Committed. Elapsed time: 1 ms.
25/05/25 08:26:06 INFO Executor: Finished task 24.0 in stage 1.0 (TID 77). 2351 bytes result sent to driver
25/05/25 08:26:06 INFO TaskSetManager: Starting task 26.0 in stage 1.0 (TID 79) (desktop-fedora, executor driver, partition 26, NODE_LOCAL, 8817 bytes) 
25/05/25 08:26:06 INFO TaskSetManager: Finished task 24.0 in stage 1.0 (TID 77) in 60 ms on desktop-fedora (executor driver) (19/53)
25/05/25 08:26:06 INFO Executor: Running task 26.0 in stage 1.0 (TID 79)
25/05/25 08:26:06 INFO ShuffleBlockFetcherIterator: Getting 53 (30.2 KiB) non-empty blocks including 53 (30.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/05/25 08:26:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/05/25 08:26:06 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
25/05/25 08:26:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/05/25 08:26:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/05/25 08:26:06 INFO PythonRunner: Times: total = 43, boot = -191, init = 233, finish = 1
25/05/25 08:26:06 INFO FileOutputCommitter: Saved output of task 'attempt_202505250826006785974358318424464_0008_m_000026_0' to hdfs://localhost:9000/user/giovanni/output/spark_cleaned_pruned_used_cars_data_result/_temporary/0/task_202505250826006785974358318424464_0008_m_000026
25/05/25 08:26:06 INFO SparkHadoopMapRedUtil: attempt_202505250826006785974358318424464_0008_m_000026_0: Committed. Elapsed time: 1 ms.
25/05/25 08:26:06 INFO Executor: Finished task 26.0 in stage 1.0 (TID 79). 2351 bytes result sent to driver
25/05/25 08:26:06 INFO TaskSetManager: Starting task 27.0 in stage 1.0 (TID 80) (desktop-fedora, executor driver, partition 27, NODE_LOCAL, 8817 bytes) 
25/05/25 08:26:06 INFO TaskSetManager: Finished task 26.0 in stage 1.0 (TID 79) in 58 ms on desktop-fedora (executor driver) (20/53)
25/05/25 08:26:06 INFO Executor: Running task 27.0 in stage 1.0 (TID 80)
25/05/25 08:26:06 INFO ShuffleBlockFetcherIterator: Getting 53 (27.8 KiB) non-empty blocks including 53 (27.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/05/25 08:26:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/05/25 08:26:06 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
25/05/25 08:26:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/05/25 08:26:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/05/25 08:26:06 INFO PythonRunner: Times: total = 43, boot = -146, init = 188, finish = 1
25/05/25 08:26:06 INFO FileOutputCommitter: Saved output of task 'attempt_202505250826006785974358318424464_0008_m_000027_0' to hdfs://localhost:9000/user/giovanni/output/spark_cleaned_pruned_used_cars_data_result/_temporary/0/task_202505250826006785974358318424464_0008_m_000027
25/05/25 08:26:06 INFO SparkHadoopMapRedUtil: attempt_202505250826006785974358318424464_0008_m_000027_0: Committed. Elapsed time: 1 ms.
25/05/25 08:26:06 INFO Executor: Finished task 27.0 in stage 1.0 (TID 80). 2351 bytes result sent to driver
25/05/25 08:26:06 INFO TaskSetManager: Starting task 28.0 in stage 1.0 (TID 81) (desktop-fedora, executor driver, partition 28, NODE_LOCAL, 8817 bytes) 
25/05/25 08:26:06 INFO Executor: Running task 28.0 in stage 1.0 (TID 81)
25/05/25 08:26:06 INFO TaskSetManager: Finished task 27.0 in stage 1.0 (TID 80) in 58 ms on desktop-fedora (executor driver) (21/53)
25/05/25 08:26:06 INFO ShuffleBlockFetcherIterator: Getting 53 (29.5 KiB) non-empty blocks including 53 (29.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/05/25 08:26:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/05/25 08:26:06 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
25/05/25 08:26:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/05/25 08:26:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/05/25 08:26:06 INFO PythonRunner: Times: total = 42, boot = -202, init = 243, finish = 1
25/05/25 08:26:06 INFO FileOutputCommitter: Saved output of task 'attempt_202505250826006785974358318424464_0008_m_000018_0' to hdfs://localhost:9000/user/giovanni/output/spark_cleaned_pruned_used_cars_data_result/_temporary/0/task_202505250826006785974358318424464_0008_m_000018
25/05/25 08:26:06 INFO SparkHadoopMapRedUtil: attempt_202505250826006785974358318424464_0008_m_000018_0: Committed. Elapsed time: 1 ms.
25/05/25 08:26:06 INFO Executor: Finished task 18.0 in stage 1.0 (TID 71). 2351 bytes result sent to driver
25/05/25 08:26:06 INFO TaskSetManager: Starting task 29.0 in stage 1.0 (TID 82) (desktop-fedora, executor driver, partition 29, NODE_LOCAL, 8817 bytes) 
25/05/25 08:26:06 INFO Executor: Running task 29.0 in stage 1.0 (TID 82)
25/05/25 08:26:06 INFO TaskSetManager: Finished task 18.0 in stage 1.0 (TID 71) in 459 ms on desktop-fedora (executor driver) (22/53)
25/05/25 08:26:06 INFO ShuffleBlockFetcherIterator: Getting 53 (20.9 KiB) non-empty blocks including 53 (20.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/05/25 08:26:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/05/25 08:26:06 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
25/05/25 08:26:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/05/25 08:26:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/05/25 08:26:06 INFO PythonRunner: Times: total = 43, boot = -303, init = 345, finish = 1
25/05/25 08:26:06 INFO FileOutputCommitter: Saved output of task 'attempt_202505250826006785974358318424464_0008_m_000029_0' to hdfs://localhost:9000/user/giovanni/output/spark_cleaned_pruned_used_cars_data_result/_temporary/0/task_202505250826006785974358318424464_0008_m_000029
25/05/25 08:26:06 INFO SparkHadoopMapRedUtil: attempt_202505250826006785974358318424464_0008_m_000029_0: Committed. Elapsed time: 1 ms.
25/05/25 08:26:06 INFO Executor: Finished task 29.0 in stage 1.0 (TID 82). 2351 bytes result sent to driver
25/05/25 08:26:06 INFO TaskSetManager: Starting task 30.0 in stage 1.0 (TID 83) (desktop-fedora, executor driver, partition 30, NODE_LOCAL, 8817 bytes) 
25/05/25 08:26:06 INFO Executor: Running task 30.0 in stage 1.0 (TID 83)
25/05/25 08:26:06 INFO TaskSetManager: Finished task 29.0 in stage 1.0 (TID 82) in 57 ms on desktop-fedora (executor driver) (23/53)
25/05/25 08:26:06 INFO ShuffleBlockFetcherIterator: Getting 53 (38.8 KiB) non-empty blocks including 53 (38.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/05/25 08:26:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/05/25 08:26:06 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
25/05/25 08:26:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/05/25 08:26:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/05/25 08:26:06 INFO FileOutputCommitter: Saved output of task 'attempt_202505250826006785974358318424464_0008_m_000020_0' to hdfs://localhost:9000/user/giovanni/output/spark_cleaned_pruned_used_cars_data_result/_temporary/0/task_202505250826006785974358318424464_0008_m_000020
25/05/25 08:26:06 INFO SparkHadoopMapRedUtil: attempt_202505250826006785974358318424464_0008_m_000020_0: Committed. Elapsed time: 1 ms.
25/05/25 08:26:06 INFO FileOutputCommitter: Saved output of task 'attempt_202505250826006785974358318424464_0008_m_000019_0' to hdfs://localhost:9000/user/giovanni/output/spark_cleaned_pruned_used_cars_data_result/_temporary/0/task_202505250826006785974358318424464_0008_m_000019
25/05/25 08:26:06 INFO SparkHadoopMapRedUtil: attempt_202505250826006785974358318424464_0008_m_000019_0: Committed. Elapsed time: 1 ms.
25/05/25 08:26:06 INFO FileOutputCommitter: Saved output of task 'attempt_202505250826006785974358318424464_0008_m_000021_0' to hdfs://localhost:9000/user/giovanni/output/spark_cleaned_pruned_used_cars_data_result/_temporary/0/task_202505250826006785974358318424464_0008_m_000021
25/05/25 08:26:06 INFO SparkHadoopMapRedUtil: attempt_202505250826006785974358318424464_0008_m_000021_0: Committed. Elapsed time: 1 ms.
25/05/25 08:26:06 INFO Executor: Finished task 20.0 in stage 1.0 (TID 73). 2351 bytes result sent to driver
25/05/25 08:26:06 INFO Executor: Finished task 21.0 in stage 1.0 (TID 74). 2351 bytes result sent to driver
25/05/25 08:26:06 INFO Executor: Finished task 19.0 in stage 1.0 (TID 72). 2351 bytes result sent to driver
25/05/25 08:26:06 INFO TaskSetManager: Starting task 31.0 in stage 1.0 (TID 84) (desktop-fedora, executor driver, partition 31, NODE_LOCAL, 8817 bytes) 
25/05/25 08:26:06 INFO Executor: Running task 31.0 in stage 1.0 (TID 84)
25/05/25 08:26:06 INFO TaskSetManager: Starting task 32.0 in stage 1.0 (TID 85) (desktop-fedora, executor driver, partition 32, NODE_LOCAL, 8817 bytes) 
25/05/25 08:26:06 INFO TaskSetManager: Finished task 20.0 in stage 1.0 (TID 73) in 462 ms on desktop-fedora (executor driver) (24/53)
25/05/25 08:26:06 INFO Executor: Running task 32.0 in stage 1.0 (TID 85)
25/05/25 08:26:06 INFO TaskSetManager: Finished task 19.0 in stage 1.0 (TID 72) in 463 ms on desktop-fedora (executor driver) (25/53)
25/05/25 08:26:06 INFO TaskSetManager: Starting task 33.0 in stage 1.0 (TID 86) (desktop-fedora, executor driver, partition 33, NODE_LOCAL, 8817 bytes) 
25/05/25 08:26:06 INFO TaskSetManager: Finished task 21.0 in stage 1.0 (TID 74) in 463 ms on desktop-fedora (executor driver) (26/53)
25/05/25 08:26:06 INFO Executor: Running task 33.0 in stage 1.0 (TID 86)
25/05/25 08:26:06 INFO PythonRunner: Times: total = 44, boot = -292, init = 334, finish = 2
25/05/25 08:26:06 INFO ShuffleBlockFetcherIterator: Getting 53 (30.8 KiB) non-empty blocks including 53 (30.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/05/25 08:26:06 INFO ShuffleBlockFetcherIterator: Getting 53 (33.1 KiB) non-empty blocks including 53 (33.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/05/25 08:26:06 INFO ShuffleBlockFetcherIterator: Getting 53 (41.6 KiB) non-empty blocks including 53 (41.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/05/25 08:26:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/05/25 08:26:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/05/25 08:26:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/05/25 08:26:06 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
25/05/25 08:26:06 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
25/05/25 08:26:06 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
25/05/25 08:26:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/05/25 08:26:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/05/25 08:26:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/05/25 08:26:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/05/25 08:26:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/05/25 08:26:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/05/25 08:26:06 INFO FileOutputCommitter: Saved output of task 'attempt_202505250826006785974358318424464_0008_m_000030_0' to hdfs://localhost:9000/user/giovanni/output/spark_cleaned_pruned_used_cars_data_result/_temporary/0/task_202505250826006785974358318424464_0008_m_000030
25/05/25 08:26:06 INFO SparkHadoopMapRedUtil: attempt_202505250826006785974358318424464_0008_m_000030_0: Committed. Elapsed time: 1 ms.
25/05/25 08:26:06 INFO Executor: Finished task 30.0 in stage 1.0 (TID 83). 2351 bytes result sent to driver
25/05/25 08:26:06 INFO TaskSetManager: Starting task 34.0 in stage 1.0 (TID 87) (desktop-fedora, executor driver, partition 34, NODE_LOCAL, 8817 bytes) 
25/05/25 08:26:06 INFO TaskSetManager: Finished task 30.0 in stage 1.0 (TID 83) in 61 ms on desktop-fedora (executor driver) (27/53)
25/05/25 08:26:06 INFO Executor: Running task 34.0 in stage 1.0 (TID 87)
25/05/25 08:26:06 INFO ShuffleBlockFetcherIterator: Getting 53 (38.0 KiB) non-empty blocks including 53 (38.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/05/25 08:26:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/05/25 08:26:06 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
25/05/25 08:26:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/05/25 08:26:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/05/25 08:26:06 INFO PythonRunner: Times: total = 43, boot = -328, init = 370, finish = 1
25/05/25 08:26:06 INFO PythonRunner: Times: total = 43, boot = -337, init = 379, finish = 1
25/05/25 08:26:06 INFO PythonRunner: Times: total = 44, boot = -329, init = 372, finish = 1
25/05/25 08:26:06 INFO PythonRunner: Times: total = 44, boot = -284, init = 326, finish = 2
25/05/25 08:26:06 INFO FileOutputCommitter: Saved output of task 'attempt_202505250826006785974358318424464_0008_m_000022_0' to hdfs://localhost:9000/user/giovanni/output/spark_cleaned_pruned_used_cars_data_result/_temporary/0/task_202505250826006785974358318424464_0008_m_000022
25/05/25 08:26:06 INFO SparkHadoopMapRedUtil: attempt_202505250826006785974358318424464_0008_m_000022_0: Committed. Elapsed time: 1 ms.
25/05/25 08:26:06 INFO FileOutputCommitter: Saved output of task 'attempt_202505250826006785974358318424464_0008_m_000023_0' to hdfs://localhost:9000/user/giovanni/output/spark_cleaned_pruned_used_cars_data_result/_temporary/0/task_202505250826006785974358318424464_0008_m_000023
25/05/25 08:26:06 INFO SparkHadoopMapRedUtil: attempt_202505250826006785974358318424464_0008_m_000023_0: Committed. Elapsed time: 1 ms.
25/05/25 08:26:06 INFO FileOutputCommitter: Saved output of task 'attempt_202505250826006785974358318424464_0008_m_000034_0' to hdfs://localhost:9000/user/giovanni/output/spark_cleaned_pruned_used_cars_data_result/_temporary/0/task_202505250826006785974358318424464_0008_m_000034
25/05/25 08:26:06 INFO SparkHadoopMapRedUtil: attempt_202505250826006785974358318424464_0008_m_000034_0: Committed. Elapsed time: 1 ms.
25/05/25 08:26:06 INFO Executor: Finished task 22.0 in stage 1.0 (TID 75). 2351 bytes result sent to driver
25/05/25 08:26:06 INFO Executor: Finished task 23.0 in stage 1.0 (TID 76). 2351 bytes result sent to driver
25/05/25 08:26:06 INFO Executor: Finished task 34.0 in stage 1.0 (TID 87). 2351 bytes result sent to driver
25/05/25 08:26:06 INFO TaskSetManager: Starting task 35.0 in stage 1.0 (TID 88) (desktop-fedora, executor driver, partition 35, NODE_LOCAL, 8817 bytes) 
25/05/25 08:26:06 INFO Executor: Running task 35.0 in stage 1.0 (TID 88)
25/05/25 08:26:06 INFO TaskSetManager: Starting task 36.0 in stage 1.0 (TID 89) (desktop-fedora, executor driver, partition 36, NODE_LOCAL, 8817 bytes) 
25/05/25 08:26:06 INFO TaskSetManager: Finished task 22.0 in stage 1.0 (TID 75) in 458 ms on desktop-fedora (executor driver) (28/53)
25/05/25 08:26:06 INFO Executor: Running task 36.0 in stage 1.0 (TID 89)
25/05/25 08:26:06 INFO TaskSetManager: Finished task 23.0 in stage 1.0 (TID 76) in 457 ms on desktop-fedora (executor driver) (29/53)
25/05/25 08:26:06 INFO TaskSetManager: Starting task 37.0 in stage 1.0 (TID 90) (desktop-fedora, executor driver, partition 37, NODE_LOCAL, 8817 bytes) 
25/05/25 08:26:06 INFO TaskSetManager: Finished task 34.0 in stage 1.0 (TID 87) in 58 ms on desktop-fedora (executor driver) (30/53)
25/05/25 08:26:06 INFO Executor: Running task 37.0 in stage 1.0 (TID 90)
25/05/25 08:26:06 INFO ShuffleBlockFetcherIterator: Getting 53 (33.1 KiB) non-empty blocks including 53 (33.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/05/25 08:26:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/05/25 08:26:06 INFO ShuffleBlockFetcherIterator: Getting 53 (33.9 KiB) non-empty blocks including 53 (33.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/05/25 08:26:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/05/25 08:26:06 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
25/05/25 08:26:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/05/25 08:26:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/05/25 08:26:06 INFO ShuffleBlockFetcherIterator: Getting 53 (36.1 KiB) non-empty blocks including 53 (36.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/05/25 08:26:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/05/25 08:26:06 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
25/05/25 08:26:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/05/25 08:26:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/05/25 08:26:06 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
25/05/25 08:26:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/05/25 08:26:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/05/25 08:26:06 INFO FileOutputCommitter: Saved output of task 'attempt_202505250826006785974358318424464_0008_m_000025_0' to hdfs://localhost:9000/user/giovanni/output/spark_cleaned_pruned_used_cars_data_result/_temporary/0/task_202505250826006785974358318424464_0008_m_000025
25/05/25 08:26:06 INFO SparkHadoopMapRedUtil: attempt_202505250826006785974358318424464_0008_m_000025_0: Committed. Elapsed time: 1 ms.
25/05/25 08:26:06 INFO Executor: Finished task 25.0 in stage 1.0 (TID 78). 2351 bytes result sent to driver
25/05/25 08:26:06 INFO TaskSetManager: Starting task 38.0 in stage 1.0 (TID 91) (desktop-fedora, executor driver, partition 38, NODE_LOCAL, 8817 bytes) 
25/05/25 08:26:06 INFO TaskSetManager: Finished task 25.0 in stage 1.0 (TID 78) in 461 ms on desktop-fedora (executor driver) (31/53)
25/05/25 08:26:06 INFO Executor: Running task 38.0 in stage 1.0 (TID 91)
25/05/25 08:26:06 INFO ShuffleBlockFetcherIterator: Getting 53 (44.5 KiB) non-empty blocks including 53 (44.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/05/25 08:26:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/05/25 08:26:06 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
25/05/25 08:26:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/05/25 08:26:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/05/25 08:26:06 INFO PythonRunner: Times: total = 42, boot = -283, init = 324, finish = 1
25/05/25 08:26:06 INFO PythonRunner: Times: total = 42, boot = -230, init = 271, finish = 1
25/05/25 08:26:06 INFO PythonRunner: Times: total = 44, boot = -126, init = 168, finish = 2
25/05/25 08:26:06 INFO PythonRunner: Times: total = 44, boot = -74, init = 116, finish = 2
25/05/25 08:26:06 INFO FileOutputCommitter: Saved output of task 'attempt_202505250826006785974358318424464_0008_m_000028_0' to hdfs://localhost:9000/user/giovanni/output/spark_cleaned_pruned_used_cars_data_result/_temporary/0/task_202505250826006785974358318424464_0008_m_000028
25/05/25 08:26:06 INFO SparkHadoopMapRedUtil: attempt_202505250826006785974358318424464_0008_m_000028_0: Committed. Elapsed time: 1 ms.
25/05/25 08:26:06 INFO Executor: Finished task 28.0 in stage 1.0 (TID 81). 2351 bytes result sent to driver
25/05/25 08:26:06 INFO TaskSetManager: Starting task 39.0 in stage 1.0 (TID 92) (desktop-fedora, executor driver, partition 39, NODE_LOCAL, 8817 bytes) 
25/05/25 08:26:06 INFO TaskSetManager: Finished task 28.0 in stage 1.0 (TID 81) in 458 ms on desktop-fedora (executor driver) (32/53)
25/05/25 08:26:06 INFO Executor: Running task 39.0 in stage 1.0 (TID 92)
25/05/25 08:26:06 INFO ShuffleBlockFetcherIterator: Getting 53 (25.8 KiB) non-empty blocks including 53 (25.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/05/25 08:26:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/05/25 08:26:06 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
25/05/25 08:26:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/05/25 08:26:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/05/25 08:26:06 INFO PythonRunner: Times: total = 43, boot = -200, init = 242, finish = 1
25/05/25 08:26:06 INFO FileOutputCommitter: Saved output of task 'attempt_202505250826006785974358318424464_0008_m_000033_0' to hdfs://localhost:9000/user/giovanni/output/spark_cleaned_pruned_used_cars_data_result/_temporary/0/task_202505250826006785974358318424464_0008_m_000033
25/05/25 08:26:06 INFO SparkHadoopMapRedUtil: attempt_202505250826006785974358318424464_0008_m_000033_0: Committed. Elapsed time: 1 ms.
25/05/25 08:26:06 INFO FileOutputCommitter: Saved output of task 'attempt_202505250826006785974358318424464_0008_m_000031_0' to hdfs://localhost:9000/user/giovanni/output/spark_cleaned_pruned_used_cars_data_result/_temporary/0/task_202505250826006785974358318424464_0008_m_000031
25/05/25 08:26:06 INFO SparkHadoopMapRedUtil: attempt_202505250826006785974358318424464_0008_m_000031_0: Committed. Elapsed time: 1 ms.
25/05/25 08:26:06 INFO FileOutputCommitter: Saved output of task 'attempt_202505250826006785974358318424464_0008_m_000032_0' to hdfs://localhost:9000/user/giovanni/output/spark_cleaned_pruned_used_cars_data_result/_temporary/0/task_202505250826006785974358318424464_0008_m_000032
25/05/25 08:26:06 INFO SparkHadoopMapRedUtil: attempt_202505250826006785974358318424464_0008_m_000032_0: Committed. Elapsed time: 1 ms.
25/05/25 08:26:06 INFO Executor: Finished task 32.0 in stage 1.0 (TID 85). 2351 bytes result sent to driver
25/05/25 08:26:06 INFO Executor: Finished task 33.0 in stage 1.0 (TID 86). 2351 bytes result sent to driver
25/05/25 08:26:06 INFO Executor: Finished task 31.0 in stage 1.0 (TID 84). 2351 bytes result sent to driver
25/05/25 08:26:06 INFO TaskSetManager: Starting task 40.0 in stage 1.0 (TID 93) (desktop-fedora, executor driver, partition 40, NODE_LOCAL, 8817 bytes) 
25/05/25 08:26:06 INFO TaskSetManager: Finished task 32.0 in stage 1.0 (TID 85) in 459 ms on desktop-fedora (executor driver) (33/53)
25/05/25 08:26:06 INFO Executor: Running task 40.0 in stage 1.0 (TID 93)
25/05/25 08:26:06 INFO TaskSetManager: Starting task 41.0 in stage 1.0 (TID 94) (desktop-fedora, executor driver, partition 41, NODE_LOCAL, 8817 bytes) 
25/05/25 08:26:06 INFO Executor: Running task 41.0 in stage 1.0 (TID 94)
25/05/25 08:26:06 INFO TaskSetManager: Starting task 42.0 in stage 1.0 (TID 95) (desktop-fedora, executor driver, partition 42, NODE_LOCAL, 8817 bytes) 
25/05/25 08:26:06 INFO TaskSetManager: Finished task 33.0 in stage 1.0 (TID 86) in 459 ms on desktop-fedora (executor driver) (34/53)
25/05/25 08:26:06 INFO TaskSetManager: Finished task 31.0 in stage 1.0 (TID 84) in 459 ms on desktop-fedora (executor driver) (35/53)
25/05/25 08:26:06 INFO Executor: Running task 42.0 in stage 1.0 (TID 95)
25/05/25 08:26:06 INFO ShuffleBlockFetcherIterator: Getting 53 (33.2 KiB) non-empty blocks including 53 (33.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/05/25 08:26:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/05/25 08:26:06 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
25/05/25 08:26:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/05/25 08:26:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/05/25 08:26:06 INFO ShuffleBlockFetcherIterator: Getting 53 (47.5 KiB) non-empty blocks including 53 (47.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/05/25 08:26:06 INFO ShuffleBlockFetcherIterator: Getting 53 (32.2 KiB) non-empty blocks including 53 (32.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/05/25 08:26:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/05/25 08:26:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/05/25 08:26:06 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
25/05/25 08:26:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/05/25 08:26:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/05/25 08:26:06 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
25/05/25 08:26:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/05/25 08:26:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/05/25 08:26:07 INFO PythonRunner: Times: total = 44, boot = -405, init = 447, finish = 2
25/05/25 08:26:07 INFO PythonRunner: Times: total = 43, boot = -398, init = 400, finish = 41
25/05/25 08:26:07 INFO PythonRunner: Times: total = 44, boot = -408, init = 451, finish = 1
25/05/25 08:26:07 INFO FileOutputCommitter: Saved output of task 'attempt_202505250826006785974358318424464_0008_m_000042_0' to hdfs://localhost:9000/user/giovanni/output/spark_cleaned_pruned_used_cars_data_result/_temporary/0/task_202505250826006785974358318424464_0008_m_000042
25/05/25 08:26:07 INFO SparkHadoopMapRedUtil: attempt_202505250826006785974358318424464_0008_m_000042_0: Committed. Elapsed time: 1 ms.
25/05/25 08:26:07 INFO Executor: Finished task 42.0 in stage 1.0 (TID 95). 2351 bytes result sent to driver
25/05/25 08:26:07 INFO TaskSetManager: Starting task 43.0 in stage 1.0 (TID 96) (desktop-fedora, executor driver, partition 43, NODE_LOCAL, 8817 bytes) 
25/05/25 08:26:07 INFO TaskSetManager: Finished task 42.0 in stage 1.0 (TID 95) in 61 ms on desktop-fedora (executor driver) (36/53)
25/05/25 08:26:07 INFO Executor: Running task 43.0 in stage 1.0 (TID 96)
25/05/25 08:26:07 INFO ShuffleBlockFetcherIterator: Getting 53 (43.4 KiB) non-empty blocks including 53 (43.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/05/25 08:26:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/05/25 08:26:07 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
25/05/25 08:26:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/05/25 08:26:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/05/25 08:26:07 INFO FileOutputCommitter: Saved output of task 'attempt_202505250826006785974358318424464_0008_m_000037_0' to hdfs://localhost:9000/user/giovanni/output/spark_cleaned_pruned_used_cars_data_result/_temporary/0/task_202505250826006785974358318424464_0008_m_000037
25/05/25 08:26:07 INFO SparkHadoopMapRedUtil: attempt_202505250826006785974358318424464_0008_m_000037_0: Committed. Elapsed time: 1 ms.
25/05/25 08:26:07 INFO FileOutputCommitter: Saved output of task 'attempt_202505250826006785974358318424464_0008_m_000036_0' to hdfs://localhost:9000/user/giovanni/output/spark_cleaned_pruned_used_cars_data_result/_temporary/0/task_202505250826006785974358318424464_0008_m_000036
25/05/25 08:26:07 INFO SparkHadoopMapRedUtil: attempt_202505250826006785974358318424464_0008_m_000036_0: Committed. Elapsed time: 1 ms.
25/05/25 08:26:07 INFO Executor: Finished task 37.0 in stage 1.0 (TID 90). 2351 bytes result sent to driver
25/05/25 08:26:07 INFO Executor: Finished task 36.0 in stage 1.0 (TID 89). 2351 bytes result sent to driver
25/05/25 08:26:07 INFO TaskSetManager: Starting task 44.0 in stage 1.0 (TID 97) (desktop-fedora, executor driver, partition 44, NODE_LOCAL, 8817 bytes) 
25/05/25 08:26:07 INFO TaskSetManager: Finished task 37.0 in stage 1.0 (TID 90) in 460 ms on desktop-fedora (executor driver) (37/53)
25/05/25 08:26:07 INFO Executor: Running task 44.0 in stage 1.0 (TID 97)
25/05/25 08:26:07 INFO TaskSetManager: Starting task 45.0 in stage 1.0 (TID 98) (desktop-fedora, executor driver, partition 45, NODE_LOCAL, 8817 bytes) 
25/05/25 08:26:07 INFO FileOutputCommitter: Saved output of task 'attempt_202505250826006785974358318424464_0008_m_000035_0' to hdfs://localhost:9000/user/giovanni/output/spark_cleaned_pruned_used_cars_data_result/_temporary/0/task_202505250826006785974358318424464_0008_m_000035
25/05/25 08:26:07 INFO SparkHadoopMapRedUtil: attempt_202505250826006785974358318424464_0008_m_000035_0: Committed. Elapsed time: 1 ms.
25/05/25 08:26:07 INFO TaskSetManager: Finished task 36.0 in stage 1.0 (TID 89) in 460 ms on desktop-fedora (executor driver) (38/53)
25/05/25 08:26:07 INFO Executor: Running task 45.0 in stage 1.0 (TID 98)
25/05/25 08:26:07 INFO Executor: Finished task 35.0 in stage 1.0 (TID 88). 2351 bytes result sent to driver
25/05/25 08:26:07 INFO TaskSetManager: Starting task 46.0 in stage 1.0 (TID 99) (desktop-fedora, executor driver, partition 46, NODE_LOCAL, 8817 bytes) 
25/05/25 08:26:07 INFO Executor: Running task 46.0 in stage 1.0 (TID 99)
25/05/25 08:26:07 INFO TaskSetManager: Finished task 35.0 in stage 1.0 (TID 88) in 461 ms on desktop-fedora (executor driver) (39/53)
25/05/25 08:26:07 INFO ShuffleBlockFetcherIterator: Getting 53 (49.1 KiB) non-empty blocks including 53 (49.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/05/25 08:26:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/05/25 08:26:07 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
25/05/25 08:26:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/05/25 08:26:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/05/25 08:26:07 INFO ShuffleBlockFetcherIterator: Getting 53 (30.8 KiB) non-empty blocks including 53 (30.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/05/25 08:26:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/05/25 08:26:07 INFO ShuffleBlockFetcherIterator: Getting 53 (30.2 KiB) non-empty blocks including 53 (30.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/05/25 08:26:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/05/25 08:26:07 INFO PythonRunner: Times: total = 3, boot = -405, init = 406, finish = 2
25/05/25 08:26:07 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
25/05/25 08:26:07 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
25/05/25 08:26:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/05/25 08:26:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/05/25 08:26:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/05/25 08:26:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/05/25 08:26:07 INFO FileOutputCommitter: Saved output of task 'attempt_202505250826006785974358318424464_0008_m_000038_0' to hdfs://localhost:9000/user/giovanni/output/spark_cleaned_pruned_used_cars_data_result/_temporary/0/task_202505250826006785974358318424464_0008_m_000038
25/05/25 08:26:07 INFO SparkHadoopMapRedUtil: attempt_202505250826006785974358318424464_0008_m_000038_0: Committed. Elapsed time: 1 ms.
25/05/25 08:26:07 INFO Executor: Finished task 38.0 in stage 1.0 (TID 91). 2351 bytes result sent to driver
25/05/25 08:26:07 INFO TaskSetManager: Starting task 47.0 in stage 1.0 (TID 100) (desktop-fedora, executor driver, partition 47, NODE_LOCAL, 8817 bytes) 
25/05/25 08:26:07 INFO TaskSetManager: Finished task 38.0 in stage 1.0 (TID 91) in 460 ms on desktop-fedora (executor driver) (40/53)
25/05/25 08:26:07 INFO Executor: Running task 47.0 in stage 1.0 (TID 100)
25/05/25 08:26:07 INFO ShuffleBlockFetcherIterator: Getting 53 (36.9 KiB) non-empty blocks including 53 (36.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/05/25 08:26:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/05/25 08:26:07 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
25/05/25 08:26:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/05/25 08:26:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/05/25 08:26:07 INFO PythonRunner: Times: total = 44, boot = -397, init = 440, finish = 1
25/05/25 08:26:07 INFO PythonRunner: Times: total = 43, boot = -401, init = 443, finish = 1
25/05/25 08:26:07 INFO PythonRunner: Times: total = 43, boot = -407, init = 449, finish = 1
25/05/25 08:26:07 INFO PythonRunner: Times: total = 43, boot = -241, init = 283, finish = 1
25/05/25 08:26:07 INFO FileOutputCommitter: Saved output of task 'attempt_202505250826006785974358318424464_0008_m_000039_0' to hdfs://localhost:9000/user/giovanni/output/spark_cleaned_pruned_used_cars_data_result/_temporary/0/task_202505250826006785974358318424464_0008_m_000039
25/05/25 08:26:07 INFO SparkHadoopMapRedUtil: attempt_202505250826006785974358318424464_0008_m_000039_0: Committed. Elapsed time: 1 ms.
25/05/25 08:26:07 INFO Executor: Finished task 39.0 in stage 1.0 (TID 92). 2351 bytes result sent to driver
25/05/25 08:26:07 INFO TaskSetManager: Starting task 48.0 in stage 1.0 (TID 101) (desktop-fedora, executor driver, partition 48, NODE_LOCAL, 8817 bytes) 
25/05/25 08:26:07 INFO TaskSetManager: Finished task 39.0 in stage 1.0 (TID 92) in 457 ms on desktop-fedora (executor driver) (41/53)
25/05/25 08:26:07 INFO Executor: Running task 48.0 in stage 1.0 (TID 101)
25/05/25 08:26:07 INFO ShuffleBlockFetcherIterator: Getting 53 (24.8 KiB) non-empty blocks including 53 (24.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/05/25 08:26:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/05/25 08:26:07 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
25/05/25 08:26:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/05/25 08:26:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/05/25 08:26:07 INFO PythonRunner: Times: total = 43, boot = -199, init = 241, finish = 1
25/05/25 08:26:07 INFO FileOutputCommitter: Saved output of task 'attempt_202505250826006785974358318424464_0008_m_000048_0' to hdfs://localhost:9000/user/giovanni/output/spark_cleaned_pruned_used_cars_data_result/_temporary/0/task_202505250826006785974358318424464_0008_m_000048
25/05/25 08:26:07 INFO SparkHadoopMapRedUtil: attempt_202505250826006785974358318424464_0008_m_000048_0: Committed. Elapsed time: 0 ms.
25/05/25 08:26:07 INFO Executor: Finished task 48.0 in stage 1.0 (TID 101). 2351 bytes result sent to driver
25/05/25 08:26:07 INFO TaskSetManager: Starting task 49.0 in stage 1.0 (TID 102) (desktop-fedora, executor driver, partition 49, NODE_LOCAL, 8817 bytes) 
25/05/25 08:26:07 INFO TaskSetManager: Finished task 48.0 in stage 1.0 (TID 101) in 57 ms on desktop-fedora (executor driver) (42/53)
25/05/25 08:26:07 INFO Executor: Running task 49.0 in stage 1.0 (TID 102)
25/05/25 08:26:07 INFO ShuffleBlockFetcherIterator: Getting 53 (39.3 KiB) non-empty blocks including 53 (39.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/05/25 08:26:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/05/25 08:26:07 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
25/05/25 08:26:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/05/25 08:26:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/05/25 08:26:07 INFO PythonRunner: Times: total = 43, boot = -252, init = 294, finish = 1
25/05/25 08:26:07 INFO FileOutputCommitter: Saved output of task 'attempt_202505250826006785974358318424464_0008_m_000049_0' to hdfs://localhost:9000/user/giovanni/output/spark_cleaned_pruned_used_cars_data_result/_temporary/0/task_202505250826006785974358318424464_0008_m_000049
25/05/25 08:26:07 INFO SparkHadoopMapRedUtil: attempt_202505250826006785974358318424464_0008_m_000049_0: Committed. Elapsed time: 1 ms.
25/05/25 08:26:07 INFO Executor: Finished task 49.0 in stage 1.0 (TID 102). 2351 bytes result sent to driver
25/05/25 08:26:07 INFO TaskSetManager: Starting task 50.0 in stage 1.0 (TID 103) (desktop-fedora, executor driver, partition 50, NODE_LOCAL, 8817 bytes) 
25/05/25 08:26:07 INFO TaskSetManager: Finished task 49.0 in stage 1.0 (TID 102) in 55 ms on desktop-fedora (executor driver) (43/53)
25/05/25 08:26:07 INFO Executor: Running task 50.0 in stage 1.0 (TID 103)
25/05/25 08:26:07 INFO ShuffleBlockFetcherIterator: Getting 53 (37.6 KiB) non-empty blocks including 53 (37.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/05/25 08:26:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/05/25 08:26:07 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
25/05/25 08:26:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/05/25 08:26:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/05/25 08:26:07 INFO PythonRunner: Times: total = 43, boot = -306, init = 347, finish = 2
25/05/25 08:26:07 INFO FileOutputCommitter: Saved output of task 'attempt_202505250826006785974358318424464_0008_m_000041_0' to hdfs://localhost:9000/user/giovanni/output/spark_cleaned_pruned_used_cars_data_result/_temporary/0/task_202505250826006785974358318424464_0008_m_000041
25/05/25 08:26:07 INFO SparkHadoopMapRedUtil: attempt_202505250826006785974358318424464_0008_m_000041_0: Committed. Elapsed time: 1 ms.
25/05/25 08:26:07 INFO Executor: Finished task 41.0 in stage 1.0 (TID 94). 2351 bytes result sent to driver
25/05/25 08:26:07 INFO TaskSetManager: Starting task 51.0 in stage 1.0 (TID 104) (desktop-fedora, executor driver, partition 51, NODE_LOCAL, 8817 bytes) 
25/05/25 08:26:07 INFO FileOutputCommitter: Saved output of task 'attempt_202505250826006785974358318424464_0008_m_000040_0' to hdfs://localhost:9000/user/giovanni/output/spark_cleaned_pruned_used_cars_data_result/_temporary/0/task_202505250826006785974358318424464_0008_m_000040
25/05/25 08:26:07 INFO SparkHadoopMapRedUtil: attempt_202505250826006785974358318424464_0008_m_000040_0: Committed. Elapsed time: 1 ms.
25/05/25 08:26:07 INFO TaskSetManager: Finished task 41.0 in stage 1.0 (TID 94) in 458 ms on desktop-fedora (executor driver) (44/53)
25/05/25 08:26:07 INFO Executor: Running task 51.0 in stage 1.0 (TID 104)
25/05/25 08:26:07 INFO Executor: Finished task 40.0 in stage 1.0 (TID 93). 2351 bytes result sent to driver
25/05/25 08:26:07 INFO TaskSetManager: Starting task 52.0 in stage 1.0 (TID 105) (desktop-fedora, executor driver, partition 52, NODE_LOCAL, 8817 bytes) 
25/05/25 08:26:07 INFO TaskSetManager: Finished task 40.0 in stage 1.0 (TID 93) in 458 ms on desktop-fedora (executor driver) (45/53)
25/05/25 08:26:07 INFO Executor: Running task 52.0 in stage 1.0 (TID 105)
25/05/25 08:26:07 INFO ShuffleBlockFetcherIterator: Getting 53 (37.9 KiB) non-empty blocks including 53 (37.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/05/25 08:26:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/05/25 08:26:07 INFO ShuffleBlockFetcherIterator: Getting 53 (44.8 KiB) non-empty blocks including 53 (44.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
25/05/25 08:26:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
25/05/25 08:26:07 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
25/05/25 08:26:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/05/25 08:26:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/05/25 08:26:07 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
25/05/25 08:26:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
25/05/25 08:26:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
25/05/25 08:26:07 INFO PythonRunner: Times: total = 3, boot = -347, init = 348, finish = 2
25/05/25 08:26:07 INFO FileOutputCommitter: Saved output of task 'attempt_202505250826006785974358318424464_0008_m_000044_0' to hdfs://localhost:9000/user/giovanni/output/spark_cleaned_pruned_used_cars_data_result/_temporary/0/task_202505250826006785974358318424464_0008_m_000044
25/05/25 08:26:07 INFO SparkHadoopMapRedUtil: attempt_202505250826006785974358318424464_0008_m_000044_0: Committed. Elapsed time: 1 ms.
25/05/25 08:26:07 INFO Executor: Finished task 44.0 in stage 1.0 (TID 97). 2351 bytes result sent to driver
25/05/25 08:26:07 INFO TaskSetManager: Finished task 44.0 in stage 1.0 (TID 97) in 417 ms on desktop-fedora (executor driver) (46/53)
25/05/25 08:26:07 INFO PythonRunner: Times: total = 43, boot = -376, init = 418, finish = 1
25/05/25 08:26:07 INFO FileOutputCommitter: Saved output of task 'attempt_202505250826006785974358318424464_0008_m_000051_0' to hdfs://localhost:9000/user/giovanni/output/spark_cleaned_pruned_used_cars_data_result/_temporary/0/task_202505250826006785974358318424464_0008_m_000051
25/05/25 08:26:07 INFO SparkHadoopMapRedUtil: attempt_202505250826006785974358318424464_0008_m_000051_0: Committed. Elapsed time: 1 ms.
25/05/25 08:26:07 INFO Executor: Finished task 51.0 in stage 1.0 (TID 104). 2351 bytes result sent to driver
25/05/25 08:26:07 INFO TaskSetManager: Finished task 51.0 in stage 1.0 (TID 104) in 55 ms on desktop-fedora (executor driver) (47/53)
25/05/25 08:26:07 INFO FileOutputCommitter: Saved output of task 'attempt_202505250826006785974358318424464_0008_m_000043_0' to hdfs://localhost:9000/user/giovanni/output/spark_cleaned_pruned_used_cars_data_result/_temporary/0/task_202505250826006785974358318424464_0008_m_000043
25/05/25 08:26:07 INFO SparkHadoopMapRedUtil: attempt_202505250826006785974358318424464_0008_m_000043_0: Committed. Elapsed time: 1 ms.
25/05/25 08:26:07 INFO Executor: Finished task 43.0 in stage 1.0 (TID 96). 2351 bytes result sent to driver
25/05/25 08:26:07 INFO TaskSetManager: Finished task 43.0 in stage 1.0 (TID 96) in 458 ms on desktop-fedora (executor driver) (48/53)
25/05/25 08:26:07 INFO FileOutputCommitter: Saved output of task 'attempt_202505250826006785974358318424464_0008_m_000045_0' to hdfs://localhost:9000/user/giovanni/output/spark_cleaned_pruned_used_cars_data_result/_temporary/0/task_202505250826006785974358318424464_0008_m_000045
25/05/25 08:26:07 INFO SparkHadoopMapRedUtil: attempt_202505250826006785974358318424464_0008_m_000045_0: Committed. Elapsed time: 1 ms.
25/05/25 08:26:07 INFO FileOutputCommitter: Saved output of task 'attempt_202505250826006785974358318424464_0008_m_000046_0' to hdfs://localhost:9000/user/giovanni/output/spark_cleaned_pruned_used_cars_data_result/_temporary/0/task_202505250826006785974358318424464_0008_m_000046
25/05/25 08:26:07 INFO SparkHadoopMapRedUtil: attempt_202505250826006785974358318424464_0008_m_000046_0: Committed. Elapsed time: 1 ms.
25/05/25 08:26:07 INFO Executor: Finished task 45.0 in stage 1.0 (TID 98). 2351 bytes result sent to driver
25/05/25 08:26:07 INFO Executor: Finished task 46.0 in stage 1.0 (TID 99). 2351 bytes result sent to driver
25/05/25 08:26:07 INFO TaskSetManager: Finished task 45.0 in stage 1.0 (TID 98) in 459 ms on desktop-fedora (executor driver) (49/53)
25/05/25 08:26:07 INFO TaskSetManager: Finished task 46.0 in stage 1.0 (TID 99) in 458 ms on desktop-fedora (executor driver) (50/53)
25/05/25 08:26:07 INFO FileOutputCommitter: Saved output of task 'attempt_202505250826006785974358318424464_0008_m_000047_0' to hdfs://localhost:9000/user/giovanni/output/spark_cleaned_pruned_used_cars_data_result/_temporary/0/task_202505250826006785974358318424464_0008_m_000047
25/05/25 08:26:07 INFO SparkHadoopMapRedUtil: attempt_202505250826006785974358318424464_0008_m_000047_0: Committed. Elapsed time: 1 ms.
25/05/25 08:26:07 INFO Executor: Finished task 47.0 in stage 1.0 (TID 100). 2351 bytes result sent to driver
25/05/25 08:26:07 INFO TaskSetManager: Finished task 47.0 in stage 1.0 (TID 100) in 454 ms on desktop-fedora (executor driver) (51/53)
25/05/25 08:26:07 INFO FileOutputCommitter: Saved output of task 'attempt_202505250826006785974358318424464_0008_m_000050_0' to hdfs://localhost:9000/user/giovanni/output/spark_cleaned_pruned_used_cars_data_result/_temporary/0/task_202505250826006785974358318424464_0008_m_000050
25/05/25 08:26:07 INFO SparkHadoopMapRedUtil: attempt_202505250826006785974358318424464_0008_m_000050_0: Committed. Elapsed time: 1 ms.
25/05/25 08:26:07 INFO Executor: Finished task 50.0 in stage 1.0 (TID 103). 2394 bytes result sent to driver
25/05/25 08:26:07 INFO TaskSetManager: Finished task 50.0 in stage 1.0 (TID 103) in 456 ms on desktop-fedora (executor driver) (52/53)
25/05/25 08:26:07 INFO FileOutputCommitter: Saved output of task 'attempt_202505250826006785974358318424464_0008_m_000052_0' to hdfs://localhost:9000/user/giovanni/output/spark_cleaned_pruned_used_cars_data_result/_temporary/0/task_202505250826006785974358318424464_0008_m_000052
25/05/25 08:26:07 INFO SparkHadoopMapRedUtil: attempt_202505250826006785974358318424464_0008_m_000052_0: Committed. Elapsed time: 1 ms.
25/05/25 08:26:07 INFO Executor: Finished task 52.0 in stage 1.0 (TID 105). 2394 bytes result sent to driver
25/05/25 08:26:07 INFO TaskSetManager: Finished task 52.0 in stage 1.0 (TID 105) in 415 ms on desktop-fedora (executor driver) (53/53)
25/05/25 08:26:07 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
25/05/25 08:26:07 INFO DAGScheduler: ResultStage 1 (runJob at SparkHadoopWriter.scala:83) finished in 2.357 s
25/05/25 08:26:07 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/25 08:26:07 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
25/05/25 08:26:07 INFO DAGScheduler: Job 0 finished: runJob at SparkHadoopWriter.scala:83, took 7.370866 s
25/05/25 08:26:07 INFO SparkHadoopWriter: Start to commit write Job job_202505250826006785974358318424464_0008.
25/05/25 08:26:07 INFO SparkHadoopWriter: Write Job job_202505250826006785974358318424464_0008 committed. Elapsed time: 48 ms.
25/05/25 08:26:07 INFO SparkContext: Invoking stop() from shutdown hook
25/05/25 08:26:07 INFO SparkContext: SparkContext is stopping with exitCode 0.
25/05/25 08:26:07 INFO SparkUI: Stopped Spark web UI at http://desktop-fedora:4040
25/05/25 08:26:07 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/05/25 08:26:07 INFO MemoryStore: MemoryStore cleared
25/05/25 08:26:07 INFO BlockManager: BlockManager stopped
25/05/25 08:26:07 INFO BlockManagerMaster: BlockManagerMaster stopped
25/05/25 08:26:07 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/05/25 08:26:07 INFO SparkContext: Successfully stopped SparkContext
25/05/25 08:26:07 INFO ShutdownHookManager: Shutdown hook called
25/05/25 08:26:07 INFO ShutdownHookManager: Deleting directory /tmp/spark-069c1d66-5df5-42e3-85d5-3ebc9b1e3516
25/05/25 08:26:07 INFO ShutdownHookManager: Deleting directory /tmp/spark-4636f8f6-2b36-430f-833c-5da16f0b08ce
25/05/25 08:26:07 INFO ShutdownHookManager: Deleting directory /tmp/spark-069c1d66-5df5-42e3-85d5-3ebc9b1e3516/pyspark-500fcca1-3451-4805-8980-4afa7c79d182
